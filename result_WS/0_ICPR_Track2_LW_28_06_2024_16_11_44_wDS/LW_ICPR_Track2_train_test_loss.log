epoch: 0.000000:	train_loss: 0.999536:	test_loss: 0.999397:	
epoch: 1.000000:	train_loss: 0.999477:	test_loss: 0.999380:	
epoch: 2.000000:	train_loss: 0.999461:	test_loss: 0.999374:	
epoch: 3.000000:	train_loss: 0.999455:	test_loss: 0.999367:	
epoch: 4.000000:	train_loss: 0.999427:	test_loss: 0.999315:	
epoch: 5.000000:	train_loss: 0.999316:	test_loss: 0.999227:	
epoch: 6.000000:	train_loss: 0.999341:	test_loss: 0.999221:	
epoch: 7.000000:	train_loss: 0.999304:	test_loss: 0.999215:	
epoch: 8.000000:	train_loss: 0.999279:	test_loss: 0.999136:	
epoch: 9.000000:	train_loss: 0.998922:	test_loss: 0.998738:	
epoch: 10.000000:	train_loss: 0.998889:	test_loss: 0.998777:	
epoch: 11.000000:	train_loss: 0.998916:	test_loss: 0.998727:	
epoch: 12.000000:	train_loss: 0.998889:	test_loss: 0.998723:	
epoch: 13.000000:	train_loss: 0.998882:	test_loss: 0.998760:	
epoch: 14.000000:	train_loss: 0.998920:	test_loss: 0.998719:	
epoch: 15.000000:	train_loss: 0.998865:	test_loss: 0.998722:	
epoch: 16.000000:	train_loss: 0.998899:	test_loss: 0.998727:	
epoch: 17.000000:	train_loss: 0.998893:	test_loss: 0.998716:	
epoch: 18.000000:	train_loss: 0.998856:	test_loss: 0.998713:	
epoch: 19.000000:	train_loss: 0.998850:	test_loss: 0.998715:	
epoch: 20.000000:	train_loss: 0.998901:	test_loss: 0.998709:	
epoch: 21.000000:	train_loss: 0.998853:	test_loss: 0.998712:	
epoch: 22.000000:	train_loss: 0.998880:	test_loss: 0.998719:	
epoch: 23.000000:	train_loss: 0.998852:	test_loss: 0.998709:	
epoch: 24.000000:	train_loss: 0.998852:	test_loss: 0.998714:	
epoch: 25.000000:	train_loss: 0.998893:	test_loss: 0.998712:	
epoch: 26.000000:	train_loss: 0.998849:	test_loss: 0.998709:	
epoch: 27.000000:	train_loss: 0.998862:	test_loss: 0.998709:	
epoch: 28.000000:	train_loss: 0.998819:	test_loss: 0.998704:	
epoch: 29.000000:	train_loss: 0.998858:	test_loss: 0.998704:	
epoch: 30.000000:	train_loss: 0.998890:	test_loss: 0.998702:	
epoch: 31.000000:	train_loss: 0.998871:	test_loss: 0.998703:	
epoch: 32.000000:	train_loss: 0.998863:	test_loss: 0.998702:	
epoch: 33.000000:	train_loss: 0.998870:	test_loss: 0.998698:	
epoch: 34.000000:	train_loss: 0.998857:	test_loss: 0.998702:	
epoch: 35.000000:	train_loss: 0.998858:	test_loss: 0.998703:	
epoch: 36.000000:	train_loss: 0.998851:	test_loss: 0.998715:	
epoch: 37.000000:	train_loss: 0.998861:	test_loss: 0.998703:	
epoch: 38.000000:	train_loss: 0.998863:	test_loss: 0.998710:	
epoch: 39.000000:	train_loss: 0.998855:	test_loss: 0.998731:	
epoch: 40.000000:	train_loss: 0.998878:	test_loss: 0.998704:	
epoch: 41.000000:	train_loss: 0.998828:	test_loss: 0.998707:	
epoch: 42.000000:	train_loss: 0.998853:	test_loss: 0.998706:	
epoch: 43.000000:	train_loss: 0.998902:	test_loss: 0.998712:	
epoch: 44.000000:	train_loss: 0.998872:	test_loss: 0.998703:	
epoch: 45.000000:	train_loss: 0.998911:	test_loss: 0.998695:	
epoch: 46.000000:	train_loss: 0.998812:	test_loss: 0.998692:	
epoch: 47.000000:	train_loss: 0.998827:	test_loss: 0.998702:	
epoch: 48.000000:	train_loss: 0.998810:	test_loss: 0.998716:	
epoch: 49.000000:	train_loss: 0.998818:	test_loss: 0.998696:	
epoch: 50.000000:	train_loss: 0.998818:	test_loss: 0.998701:	
epoch: 51.000000:	train_loss: 0.998857:	test_loss: 0.998693:	
epoch: 52.000000:	train_loss: 0.998898:	test_loss: 0.998703:	
epoch: 53.000000:	train_loss: 0.998839:	test_loss: 0.998698:	
epoch: 54.000000:	train_loss: 0.998867:	test_loss: 0.998693:	
epoch: 55.000000:	train_loss: 0.998817:	test_loss: 0.998693:	
epoch: 56.000000:	train_loss: 0.998875:	test_loss: 0.998694:	
epoch: 57.000000:	train_loss: 0.998863:	test_loss: 0.998697:	
epoch: 58.000000:	train_loss: 0.998829:	test_loss: 0.998697:	
epoch: 59.000000:	train_loss: 0.998856:	test_loss: 0.998693:	
epoch: 60.000000:	train_loss: 0.998820:	test_loss: 0.998699:	
epoch: 61.000000:	train_loss: 0.998833:	test_loss: 0.998692:	
epoch: 62.000000:	train_loss: 0.998823:	test_loss: 0.998690:	
epoch: 63.000000:	train_loss: 0.998864:	test_loss: 0.998698:	
epoch: 64.000000:	train_loss: 0.998872:	test_loss: 0.998692:	
epoch: 65.000000:	train_loss: 0.998850:	test_loss: 0.998688:	
epoch: 66.000000:	train_loss: 0.998708:	test_loss: 0.998237:	
epoch: 67.000000:	train_loss: 0.998511:	test_loss: 0.998281:	
epoch: 68.000000:	train_loss: 0.998500:	test_loss: 0.998259:	
epoch: 69.000000:	train_loss: 0.998448:	test_loss: 0.998233:	
epoch: 70.000000:	train_loss: 0.998425:	test_loss: 0.998240:	
epoch: 71.000000:	train_loss: 0.998429:	test_loss: 0.998267:	
epoch: 72.000000:	train_loss: 0.998450:	test_loss: 0.998237:	
epoch: 73.000000:	train_loss: 0.998407:	test_loss: 0.998239:	
epoch: 74.000000:	train_loss: 0.998447:	test_loss: 0.998228:	
epoch: 75.000000:	train_loss: 0.998430:	test_loss: 0.998246:	
epoch: 76.000000:	train_loss: 0.998432:	test_loss: 0.998241:	
epoch: 77.000000:	train_loss: 0.998444:	test_loss: 0.998249:	
epoch: 78.000000:	train_loss: 0.998451:	test_loss: 0.998230:	
epoch: 79.000000:	train_loss: 0.998471:	test_loss: 0.998230:	
epoch: 80.000000:	train_loss: 0.998494:	test_loss: 0.998238:	
epoch: 81.000000:	train_loss: 0.998487:	test_loss: 0.998234:	
epoch: 82.000000:	train_loss: 0.998453:	test_loss: 0.998229:	
epoch: 83.000000:	train_loss: 0.998537:	test_loss: 0.998242:	
epoch: 84.000000:	train_loss: 0.998426:	test_loss: 0.998228:	
epoch: 85.000000:	train_loss: 0.998455:	test_loss: 0.998228:	
epoch: 86.000000:	train_loss: 0.998466:	test_loss: 0.998233:	
epoch: 87.000000:	train_loss: 0.998410:	test_loss: 0.998252:	
epoch: 88.000000:	train_loss: 0.998460:	test_loss: 0.998233:	
epoch: 89.000000:	train_loss: 0.998445:	test_loss: 0.998228:	
epoch: 90.000000:	train_loss: 0.998441:	test_loss: 0.998229:	
epoch: 91.000000:	train_loss: 0.998459:	test_loss: 0.998229:	
epoch: 92.000000:	train_loss: 0.998452:	test_loss: 0.998232:	
epoch: 93.000000:	train_loss: 0.998492:	test_loss: 0.998233:	
epoch: 94.000000:	train_loss: 0.998445:	test_loss: 0.998230:	
epoch: 95.000000:	train_loss: 0.998423:	test_loss: 0.998238:	
epoch: 96.000000:	train_loss: 0.998442:	test_loss: 0.998227:	
epoch: 97.000000:	train_loss: 0.998420:	test_loss: 0.998233:	
epoch: 98.000000:	train_loss: 0.998436:	test_loss: 0.998229:	
epoch: 99.000000:	train_loss: 0.998383:	test_loss: 0.998238:	
epoch: 100.000000:	train_loss: 0.998496:	test_loss: 0.998227:	
epoch: 101.000000:	train_loss: 0.998367:	test_loss: 0.998234:	
epoch: 102.000000:	train_loss: 0.998449:	test_loss: 0.998237:	
epoch: 103.000000:	train_loss: 0.998418:	test_loss: 0.998222:	
epoch: 104.000000:	train_loss: 0.998465:	test_loss: 0.998226:	
epoch: 105.000000:	train_loss: 0.998429:	test_loss: 0.998231:	
epoch: 106.000000:	train_loss: 0.998453:	test_loss: 0.998230:	
epoch: 107.000000:	train_loss: 0.998414:	test_loss: 0.998227:	
epoch: 108.000000:	train_loss: 0.997506:	test_loss: 0.998746:	
epoch: 109.000000:	train_loss: 0.998373:	test_loss: 0.998746:	
epoch: 110.000000:	train_loss: 0.997892:	test_loss: 0.998746:	
epoch: 111.000000:	train_loss: 0.998209:	test_loss: 0.998746:	
epoch: 112.000000:	train_loss: 0.998194:	test_loss: 0.998746:	
epoch: 113.000000:	train_loss: 0.998187:	test_loss: 0.998746:	
epoch: 114.000000:	train_loss: 0.998025:	test_loss: 0.998746:	
epoch: 115.000000:	train_loss: 0.998157:	test_loss: 0.998746:	
epoch: 116.000000:	train_loss: 0.998222:	test_loss: 0.998746:	
epoch: 117.000000:	train_loss: 0.998201:	test_loss: 0.998746:	
epoch: 118.000000:	train_loss: 0.997897:	test_loss: 0.998746:	
epoch: 119.000000:	train_loss: 0.998279:	test_loss: 0.998746:	
epoch: 120.000000:	train_loss: 0.998312:	test_loss: 0.998746:	
epoch: 121.000000:	train_loss: 0.998300:	test_loss: 0.998746:	
epoch: 122.000000:	train_loss: 0.998261:	test_loss: 0.998746:	
epoch: 123.000000:	train_loss: 0.998141:	test_loss: 0.998746:	
epoch: 124.000000:	train_loss: 0.998234:	test_loss: 0.998746:	
epoch: 125.000000:	train_loss: 0.998096:	test_loss: 0.998746:	
epoch: 126.000000:	train_loss: 0.998146:	test_loss: 0.998746:	
epoch: 127.000000:	train_loss: 0.998210:	test_loss: 0.998746:	
epoch: 128.000000:	train_loss: 0.998302:	test_loss: 0.998746:	
epoch: 129.000000:	train_loss: 0.998072:	test_loss: 0.998746:	
epoch: 130.000000:	train_loss: 0.998070:	test_loss: 0.998746:	
epoch: 131.000000:	train_loss: 0.998282:	test_loss: 0.998746:	
epoch: 132.000000:	train_loss: 0.998245:	test_loss: 0.998746:	
epoch: 133.000000:	train_loss: 0.998199:	test_loss: 0.998746:	
epoch: 134.000000:	train_loss: 0.998273:	test_loss: 0.998746:	
epoch: 135.000000:	train_loss: 0.998125:	test_loss: 0.998746:	
epoch: 136.000000:	train_loss: 0.998197:	test_loss: 0.998746:	
epoch: 137.000000:	train_loss: 0.998085:	test_loss: 0.998746:	
epoch: 138.000000:	train_loss: 0.997996:	test_loss: 0.998746:	
epoch: 139.000000:	train_loss: 0.998250:	test_loss: 0.998746:	
epoch: 140.000000:	train_loss: 0.998262:	test_loss: 0.998746:	
epoch: 141.000000:	train_loss: 0.998243:	test_loss: 0.998746:	
epoch: 142.000000:	train_loss: 0.998364:	test_loss: 0.998746:	
epoch: 143.000000:	train_loss: 0.998170:	test_loss: 0.998746:	
epoch: 144.000000:	train_loss: 0.998267:	test_loss: 0.998746:	
epoch: 145.000000:	train_loss: 0.998084:	test_loss: 0.998746:	
epoch: 146.000000:	train_loss: 0.998255:	test_loss: 0.998746:	
epoch: 147.000000:	train_loss: 0.998038:	test_loss: 0.998746:	
epoch: 148.000000:	train_loss: 0.998174:	test_loss: 0.998746:	
epoch: 149.000000:	train_loss: 0.998205:	test_loss: 0.998746:	
epoch: 150.000000:	train_loss: 0.998123:	test_loss: 0.998746:	
epoch: 151.000000:	train_loss: 0.998151:	test_loss: 0.998746:	
epoch: 152.000000:	train_loss: 0.997449:	test_loss: 0.998746:	
epoch: 153.000000:	train_loss: 0.998259:	test_loss: 0.998746:	
epoch: 154.000000:	train_loss: 0.998218:	test_loss: 0.998746:	
epoch: 155.000000:	train_loss: 0.998289:	test_loss: 0.998746:	
epoch: 156.000000:	train_loss: 0.998248:	test_loss: 0.998746:	
epoch: 157.000000:	train_loss: 0.998229:	test_loss: 0.998746:	
epoch: 158.000000:	train_loss: 0.998129:	test_loss: 0.998746:	
epoch: 159.000000:	train_loss: 0.998100:	test_loss: 0.998746:	
epoch: 160.000000:	train_loss: 0.998293:	test_loss: 0.998746:	
epoch: 161.000000:	train_loss: 0.998054:	test_loss: 0.998746:	
epoch: 162.000000:	train_loss: 0.998282:	test_loss: 0.998746:	
epoch: 163.000000:	train_loss: 0.998202:	test_loss: 0.998746:	
epoch: 164.000000:	train_loss: 0.998048:	test_loss: 0.998746:	
epoch: 165.000000:	train_loss: 0.998245:	test_loss: 0.998746:	
epoch: 166.000000:	train_loss: 0.998211:	test_loss: 0.998746:	
epoch: 167.000000:	train_loss: 0.998076:	test_loss: 0.998746:	
epoch: 168.000000:	train_loss: 0.998000:	test_loss: 0.998746:	
epoch: 169.000000:	train_loss: 0.998257:	test_loss: 0.998746:	
epoch: 170.000000:	train_loss: 0.998140:	test_loss: 0.998746:	
epoch: 171.000000:	train_loss: 0.998172:	test_loss: 0.998746:	
epoch: 172.000000:	train_loss: 0.998190:	test_loss: 0.998746:	
epoch: 173.000000:	train_loss: 0.998056:	test_loss: 0.998746:	
epoch: 174.000000:	train_loss: 0.998195:	test_loss: 0.998746:	
epoch: 175.000000:	train_loss: 0.998137:	test_loss: 0.998746:	
epoch: 176.000000:	train_loss: 0.998175:	test_loss: 0.998746:	
epoch: 177.000000:	train_loss: 0.998086:	test_loss: 0.998746:	
epoch: 178.000000:	train_loss: 0.996006:	test_loss: 0.998746:	
epoch: 179.000000:	train_loss: 0.998157:	test_loss: 0.998746:	
epoch: 180.000000:	train_loss: 0.998095:	test_loss: 0.998746:	
epoch: 181.000000:	train_loss: 0.998229:	test_loss: 0.998746:	
epoch: 182.000000:	train_loss: 0.998167:	test_loss: 0.998746:	
epoch: 183.000000:	train_loss: 0.998279:	test_loss: 0.998746:	
epoch: 184.000000:	train_loss: 0.998009:	test_loss: 0.998746:	
epoch: 185.000000:	train_loss: 0.998155:	test_loss: 0.998746:	
epoch: 186.000000:	train_loss: 0.998364:	test_loss: 0.998746:	
epoch: 187.000000:	train_loss: 0.998152:	test_loss: 0.998746:	
epoch: 188.000000:	train_loss: 0.998185:	test_loss: 0.998746:	
epoch: 189.000000:	train_loss: 0.998105:	test_loss: 0.998746:	
epoch: 190.000000:	train_loss: 0.998030:	test_loss: 0.998746:	
epoch: 191.000000:	train_loss: 0.997487:	test_loss: 0.998746:	
epoch: 192.000000:	train_loss: 0.998196:	test_loss: 0.998746:	
epoch: 193.000000:	train_loss: 0.998258:	test_loss: 0.998746:	
epoch: 194.000000:	train_loss: 0.998296:	test_loss: 0.998746:	
epoch: 195.000000:	train_loss: 0.998016:	test_loss: 0.998746:	
epoch: 196.000000:	train_loss: 0.998151:	test_loss: 0.998746:	
epoch: 197.000000:	train_loss: 0.998255:	test_loss: 0.998746:	
epoch: 198.000000:	train_loss: 0.998101:	test_loss: 0.998746:	
epoch: 199.000000:	train_loss: 0.998014:	test_loss: 0.998746:	
epoch: 200.000000:	train_loss: 0.998172:	test_loss: 0.998746:	
epoch: 201.000000:	train_loss: 0.998193:	test_loss: 0.998746:	
epoch: 202.000000:	train_loss: 0.998159:	test_loss: 0.998746:	
epoch: 203.000000:	train_loss: 0.998211:	test_loss: 0.998746:	
epoch: 204.000000:	train_loss: 0.997987:	test_loss: 0.998746:	
epoch: 205.000000:	train_loss: 0.998254:	test_loss: 0.998746:	
epoch: 206.000000:	train_loss: 0.997897:	test_loss: 0.998746:	
epoch: 207.000000:	train_loss: 0.998063:	test_loss: 0.998746:	
epoch: 208.000000:	train_loss: 0.998091:	test_loss: 0.998746:	
epoch: 209.000000:	train_loss: 0.998249:	test_loss: 0.998746:	
epoch: 210.000000:	train_loss: 0.998300:	test_loss: 0.998746:	
epoch: 211.000000:	train_loss: 0.998243:	test_loss: 0.998746:	
epoch: 212.000000:	train_loss: 0.998134:	test_loss: 0.998746:	
epoch: 213.000000:	train_loss: 0.998170:	test_loss: 0.998746:	
epoch: 214.000000:	train_loss: 0.998094:	test_loss: 0.998746:	
