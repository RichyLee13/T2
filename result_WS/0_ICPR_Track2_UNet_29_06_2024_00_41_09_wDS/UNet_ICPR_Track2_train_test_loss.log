epoch: 0.000000:	train_loss: 0.975405:	test_loss: 0.999746:	
epoch: 1.000000:	train_loss: 0.904844:	test_loss: 0.795463:	
epoch: 2.000000:	train_loss: 0.800888:	test_loss: 0.766234:	
epoch: 3.000000:	train_loss: 0.769875:	test_loss: 0.739004:	
epoch: 4.000000:	train_loss: 0.751588:	test_loss: 0.747686:	
epoch: 5.000000:	train_loss: 0.744889:	test_loss: 0.744624:	
epoch: 6.000000:	train_loss: 0.732109:	test_loss: 0.682596:	
epoch: 7.000000:	train_loss: 0.717803:	test_loss: 0.674357:	
epoch: 8.000000:	train_loss: 0.682077:	test_loss: 0.749156:	
epoch: 9.000000:	train_loss: 0.682688:	test_loss: 0.665881:	
epoch: 10.000000:	train_loss: 0.676806:	test_loss: 0.717991:	
epoch: 11.000000:	train_loss: 0.677542:	test_loss: 0.652374:	
epoch: 12.000000:	train_loss: 0.669367:	test_loss: 0.672480:	
epoch: 13.000000:	train_loss: 0.658504:	test_loss: 0.634418:	
epoch: 14.000000:	train_loss: 0.669146:	test_loss: 0.616083:	
epoch: 15.000000:	train_loss: 0.654924:	test_loss: 0.657381:	
epoch: 16.000000:	train_loss: 0.653581:	test_loss: 0.630329:	
epoch: 17.000000:	train_loss: 0.636655:	test_loss: 0.614344:	
epoch: 18.000000:	train_loss: 0.626209:	test_loss: 0.609462:	
epoch: 19.000000:	train_loss: 0.646651:	test_loss: 0.656016:	
epoch: 20.000000:	train_loss: 0.626380:	test_loss: 0.595762:	
epoch: 21.000000:	train_loss: 0.631649:	test_loss: 0.631906:	
epoch: 22.000000:	train_loss: 0.638947:	test_loss: 0.607870:	
epoch: 23.000000:	train_loss: 0.619008:	test_loss: 0.601405:	
epoch: 24.000000:	train_loss: 0.618183:	test_loss: 0.596167:	
epoch: 25.000000:	train_loss: 0.618621:	test_loss: 0.580411:	
epoch: 26.000000:	train_loss: 0.615937:	test_loss: 0.642065:	
epoch: 27.000000:	train_loss: 0.606801:	test_loss: 0.586843:	
epoch: 28.000000:	train_loss: 0.615907:	test_loss: 0.615770:	
epoch: 29.000000:	train_loss: 0.605494:	test_loss: 0.573356:	
epoch: 30.000000:	train_loss: 0.596596:	test_loss: 0.580183:	
epoch: 31.000000:	train_loss: 0.610781:	test_loss: 0.600417:	
epoch: 32.000000:	train_loss: 0.603759:	test_loss: 0.571969:	
epoch: 33.000000:	train_loss: 0.600903:	test_loss: 0.568590:	
epoch: 34.000000:	train_loss: 0.584702:	test_loss: 0.585366:	
epoch: 35.000000:	train_loss: 0.592407:	test_loss: 0.565454:	
epoch: 36.000000:	train_loss: 0.597514:	test_loss: 0.589453:	
epoch: 37.000000:	train_loss: 0.592907:	test_loss: 0.554922:	
epoch: 38.000000:	train_loss: 0.600109:	test_loss: 0.562498:	
epoch: 39.000000:	train_loss: 0.593989:	test_loss: 0.566062:	
epoch: 40.000000:	train_loss: 0.575828:	test_loss: 0.552156:	
epoch: 41.000000:	train_loss: 0.581276:	test_loss: 0.539024:	
epoch: 42.000000:	train_loss: 0.579857:	test_loss: 0.549228:	
epoch: 43.000000:	train_loss: 0.584570:	test_loss: 0.550514:	
epoch: 44.000000:	train_loss: 0.583407:	test_loss: 0.553625:	
epoch: 45.000000:	train_loss: 0.575617:	test_loss: 0.566888:	
epoch: 46.000000:	train_loss: 0.573477:	test_loss: 0.569139:	
epoch: 47.000000:	train_loss: 0.574138:	test_loss: 0.556593:	
epoch: 48.000000:	train_loss: 0.583417:	test_loss: 0.566798:	
epoch: 49.000000:	train_loss: 0.563015:	test_loss: 0.554763:	
epoch: 50.000000:	train_loss: 0.579035:	test_loss: 0.569042:	
epoch: 51.000000:	train_loss: 0.585214:	test_loss: 0.557304:	
epoch: 52.000000:	train_loss: 0.577156:	test_loss: 0.574238:	
epoch: 53.000000:	train_loss: 0.558593:	test_loss: 0.536836:	
epoch: 54.000000:	train_loss: 0.569325:	test_loss: 0.559927:	
epoch: 55.000000:	train_loss: 0.564023:	test_loss: 0.541063:	
epoch: 56.000000:	train_loss: 0.553002:	test_loss: 0.535616:	
epoch: 57.000000:	train_loss: 0.558390:	test_loss: 0.550059:	
epoch: 58.000000:	train_loss: 0.570526:	test_loss: 0.529244:	
epoch: 59.000000:	train_loss: 0.564275:	test_loss: 0.537968:	
epoch: 60.000000:	train_loss: 0.553624:	test_loss: 0.531728:	
epoch: 61.000000:	train_loss: 0.549843:	test_loss: 0.542272:	
epoch: 62.000000:	train_loss: 0.562488:	test_loss: 0.544486:	
epoch: 63.000000:	train_loss: 0.544815:	test_loss: 0.557098:	
epoch: 64.000000:	train_loss: 0.565197:	test_loss: 0.550220:	
epoch: 65.000000:	train_loss: 0.554740:	test_loss: 0.554690:	
epoch: 66.000000:	train_loss: 0.557210:	test_loss: 0.549459:	
epoch: 67.000000:	train_loss: 0.548644:	test_loss: 0.520799:	
epoch: 68.000000:	train_loss: 0.546736:	test_loss: 0.527810:	
epoch: 69.000000:	train_loss: 0.553374:	test_loss: 0.532210:	
epoch: 70.000000:	train_loss: 0.548334:	test_loss: 0.521237:	
epoch: 71.000000:	train_loss: 0.546812:	test_loss: 0.534411:	
epoch: 72.000000:	train_loss: 0.549452:	test_loss: 0.522686:	
epoch: 73.000000:	train_loss: 0.545083:	test_loss: 0.540177:	
epoch: 74.000000:	train_loss: 0.546634:	test_loss: 0.535161:	
epoch: 75.000000:	train_loss: 0.549078:	test_loss: 0.525799:	
epoch: 76.000000:	train_loss: 0.551023:	test_loss: 0.515513:	
epoch: 77.000000:	train_loss: 0.544681:	test_loss: 0.517016:	
epoch: 78.000000:	train_loss: 0.541889:	test_loss: 0.598965:	
epoch: 79.000000:	train_loss: 0.544687:	test_loss: 0.521020:	
epoch: 80.000000:	train_loss: 0.546320:	test_loss: 0.580783:	
epoch: 81.000000:	train_loss: 0.546772:	test_loss: 0.537830:	
epoch: 82.000000:	train_loss: 0.537805:	test_loss: 0.535415:	
epoch: 83.000000:	train_loss: 0.542895:	test_loss: 0.515674:	
epoch: 84.000000:	train_loss: 0.547447:	test_loss: 0.516323:	
epoch: 85.000000:	train_loss: 0.543540:	test_loss: 0.517213:	
epoch: 86.000000:	train_loss: 0.540418:	test_loss: 0.522214:	
epoch: 87.000000:	train_loss: 0.534429:	test_loss: 0.512578:	
epoch: 88.000000:	train_loss: 0.530862:	test_loss: 0.512431:	
epoch: 89.000000:	train_loss: 0.542584:	test_loss: 0.509815:	
epoch: 90.000000:	train_loss: 0.526066:	test_loss: 0.528378:	
epoch: 91.000000:	train_loss: 0.542714:	test_loss: 0.518305:	
epoch: 92.000000:	train_loss: 0.542059:	test_loss: 0.528002:	
epoch: 93.000000:	train_loss: 0.548234:	test_loss: 0.509110:	
epoch: 94.000000:	train_loss: 0.530349:	test_loss: 0.511057:	
epoch: 95.000000:	train_loss: 0.542722:	test_loss: 0.544505:	
epoch: 96.000000:	train_loss: 0.524329:	test_loss: 0.518148:	
epoch: 97.000000:	train_loss: 0.527315:	test_loss: 0.504384:	
epoch: 98.000000:	train_loss: 0.532366:	test_loss: 0.520839:	
epoch: 99.000000:	train_loss: 0.528742:	test_loss: 0.508828:	
epoch: 100.000000:	train_loss: 0.541594:	test_loss: 0.514998:	
epoch: 101.000000:	train_loss: 0.543152:	test_loss: 0.581449:	
epoch: 102.000000:	train_loss: 0.534492:	test_loss: 0.512760:	
epoch: 103.000000:	train_loss: 0.525951:	test_loss: 0.514823:	
epoch: 104.000000:	train_loss: 0.528589:	test_loss: 0.498464:	
epoch: 105.000000:	train_loss: 0.536119:	test_loss: 0.516164:	
epoch: 106.000000:	train_loss: 0.540356:	test_loss: 0.515210:	
epoch: 107.000000:	train_loss: 0.520472:	test_loss: 0.507926:	
epoch: 108.000000:	train_loss: 0.531958:	test_loss: 0.518920:	
epoch: 109.000000:	train_loss: 0.520334:	test_loss: 0.505575:	
epoch: 110.000000:	train_loss: 0.526466:	test_loss: 0.516874:	
epoch: 111.000000:	train_loss: 0.529644:	test_loss: 0.512626:	
epoch: 112.000000:	train_loss: 0.528471:	test_loss: 0.507010:	
epoch: 113.000000:	train_loss: 0.518427:	test_loss: 0.522165:	
epoch: 114.000000:	train_loss: 0.529732:	test_loss: 0.512519:	
epoch: 115.000000:	train_loss: 0.524778:	test_loss: 0.514654:	
epoch: 116.000000:	train_loss: 0.537398:	test_loss: 0.505842:	
epoch: 117.000000:	train_loss: 0.528973:	test_loss: 0.501507:	
epoch: 118.000000:	train_loss: 0.528480:	test_loss: 0.506257:	
epoch: 119.000000:	train_loss: 0.528994:	test_loss: 0.499271:	
epoch: 120.000000:	train_loss: 0.520488:	test_loss: 0.498185:	
epoch: 121.000000:	train_loss: 0.532322:	test_loss: 0.499568:	
epoch: 122.000000:	train_loss: 0.521171:	test_loss: 0.516833:	
epoch: 123.000000:	train_loss: 0.519871:	test_loss: 0.525522:	
epoch: 124.000000:	train_loss: 0.520678:	test_loss: 0.513564:	
epoch: 125.000000:	train_loss: 0.531271:	test_loss: 0.498365:	
epoch: 126.000000:	train_loss: 0.529206:	test_loss: 0.492711:	
epoch: 127.000000:	train_loss: 0.518137:	test_loss: 0.502823:	
epoch: 128.000000:	train_loss: 0.514209:	test_loss: 0.513064:	
epoch: 129.000000:	train_loss: 0.528812:	test_loss: 0.492520:	
epoch: 130.000000:	train_loss: 0.517546:	test_loss: 0.506846:	
epoch: 131.000000:	train_loss: 0.515970:	test_loss: 0.493153:	
epoch: 132.000000:	train_loss: 0.513387:	test_loss: 0.509504:	
epoch: 133.000000:	train_loss: 0.516629:	test_loss: 0.491393:	
epoch: 134.000000:	train_loss: 0.520062:	test_loss: 0.503077:	
epoch: 135.000000:	train_loss: 0.526212:	test_loss: 0.493057:	
epoch: 136.000000:	train_loss: 0.516404:	test_loss: 0.513416:	
epoch: 137.000000:	train_loss: 0.520532:	test_loss: 0.484394:	
epoch: 138.000000:	train_loss: 0.513546:	test_loss: 0.496614:	
epoch: 139.000000:	train_loss: 0.519335:	test_loss: 0.506622:	
epoch: 140.000000:	train_loss: 0.526494:	test_loss: 0.495851:	
epoch: 141.000000:	train_loss: 0.514299:	test_loss: 0.518078:	
epoch: 142.000000:	train_loss: 0.530613:	test_loss: 0.494372:	
epoch: 143.000000:	train_loss: 0.509835:	test_loss: 0.491102:	
epoch: 144.000000:	train_loss: 0.514732:	test_loss: 0.495916:	
epoch: 145.000000:	train_loss: 0.518760:	test_loss: 0.488754:	
epoch: 146.000000:	train_loss: 0.523696:	test_loss: 0.488532:	
epoch: 147.000000:	train_loss: 0.517067:	test_loss: 0.498329:	
epoch: 148.000000:	train_loss: 0.523425:	test_loss: 0.492053:	
epoch: 149.000000:	train_loss: 0.524449:	test_loss: 0.490071:	
epoch: 150.000000:	train_loss: 0.512454:	test_loss: 0.494371:	
epoch: 151.000000:	train_loss: 0.510627:	test_loss: 0.497327:	
epoch: 152.000000:	train_loss: 0.513472:	test_loss: 0.494076:	
epoch: 153.000000:	train_loss: 0.513669:	test_loss: 0.490746:	
epoch: 154.000000:	train_loss: 0.512212:	test_loss: 0.497607:	
epoch: 155.000000:	train_loss: 0.517721:	test_loss: 0.486932:	
epoch: 156.000000:	train_loss: 0.520881:	test_loss: 0.498044:	
epoch: 157.000000:	train_loss: 0.513178:	test_loss: 0.482338:	
epoch: 158.000000:	train_loss: 0.517833:	test_loss: 0.490119:	
epoch: 159.000000:	train_loss: 0.515249:	test_loss: 0.501558:	
epoch: 160.000000:	train_loss: 0.518633:	test_loss: 0.491202:	
epoch: 161.000000:	train_loss: 0.513691:	test_loss: 0.493332:	
epoch: 162.000000:	train_loss: 0.509812:	test_loss: 0.484808:	
epoch: 163.000000:	train_loss: 0.509195:	test_loss: 0.485347:	
epoch: 164.000000:	train_loss: 0.516515:	test_loss: 0.483707:	
epoch: 165.000000:	train_loss: 0.510421:	test_loss: 0.490419:	
epoch: 166.000000:	train_loss: 0.513331:	test_loss: 0.495619:	
epoch: 167.000000:	train_loss: 0.502465:	test_loss: 0.487727:	
epoch: 168.000000:	train_loss: 0.506198:	test_loss: 0.501082:	
epoch: 169.000000:	train_loss: 0.505618:	test_loss: 0.490307:	
epoch: 170.000000:	train_loss: 0.513706:	test_loss: 0.490648:	
epoch: 171.000000:	train_loss: 0.509285:	test_loss: 0.488735:	
epoch: 172.000000:	train_loss: 0.516046:	test_loss: 0.486197:	
epoch: 173.000000:	train_loss: 0.503054:	test_loss: 0.486512:	
epoch: 174.000000:	train_loss: 0.506230:	test_loss: 0.483126:	
epoch: 175.000000:	train_loss: 0.521199:	test_loss: 0.494596:	
epoch: 176.000000:	train_loss: 0.514525:	test_loss: 0.505340:	
epoch: 177.000000:	train_loss: 0.512632:	test_loss: 0.488951:	
epoch: 178.000000:	train_loss: 0.506325:	test_loss: 0.490097:	
epoch: 179.000000:	train_loss: 0.517806:	test_loss: 0.486104:	
epoch: 180.000000:	train_loss: 0.516647:	test_loss: 0.482280:	
epoch: 181.000000:	train_loss: 0.504918:	test_loss: 0.485531:	
epoch: 182.000000:	train_loss: 0.500041:	test_loss: 0.488984:	
epoch: 183.000000:	train_loss: 0.510523:	test_loss: 0.490435:	
epoch: 184.000000:	train_loss: 0.502427:	test_loss: 0.474049:	
epoch: 185.000000:	train_loss: 0.503513:	test_loss: 0.481571:	
epoch: 186.000000:	train_loss: 0.500940:	test_loss: 0.481463:	
epoch: 187.000000:	train_loss: 0.511466:	test_loss: 0.489416:	
epoch: 188.000000:	train_loss: 0.512528:	test_loss: 0.486640:	
epoch: 189.000000:	train_loss: 0.506096:	test_loss: 0.484195:	
epoch: 190.000000:	train_loss: 0.510362:	test_loss: 0.491094:	
epoch: 191.000000:	train_loss: 0.504716:	test_loss: 0.501520:	
epoch: 192.000000:	train_loss: 0.498663:	test_loss: 0.482198:	
epoch: 193.000000:	train_loss: 0.501642:	test_loss: 0.480744:	
epoch: 194.000000:	train_loss: 0.501785:	test_loss: 0.485071:	
epoch: 195.000000:	train_loss: 0.509147:	test_loss: 0.484943:	
epoch: 196.000000:	train_loss: 0.499045:	test_loss: 0.485504:	
epoch: 197.000000:	train_loss: 0.509308:	test_loss: 0.489350:	
epoch: 198.000000:	train_loss: 0.500125:	test_loss: 0.492816:	
epoch: 199.000000:	train_loss: 0.504808:	test_loss: 0.477520:	
epoch: 200.000000:	train_loss: 0.503196:	test_loss: 0.534620:	
epoch: 201.000000:	train_loss: 0.496566:	test_loss: 0.488649:	
epoch: 202.000000:	train_loss: 0.492526:	test_loss: 0.484479:	
epoch: 203.000000:	train_loss: 0.507400:	test_loss: 0.491912:	
epoch: 204.000000:	train_loss: 0.515448:	test_loss: 0.489078:	
epoch: 205.000000:	train_loss: 0.512274:	test_loss: 0.494226:	
epoch: 206.000000:	train_loss: 0.500074:	test_loss: 0.490505:	
epoch: 207.000000:	train_loss: 0.513557:	test_loss: 0.489007:	
epoch: 208.000000:	train_loss: 0.498426:	test_loss: 0.475562:	
epoch: 209.000000:	train_loss: 0.507427:	test_loss: 0.479405:	
epoch: 210.000000:	train_loss: 0.505474:	test_loss: 0.475064:	
epoch: 211.000000:	train_loss: 0.503648:	test_loss: 0.481564:	
epoch: 212.000000:	train_loss: 0.509325:	test_loss: 0.482305:	
epoch: 213.000000:	train_loss: 0.502390:	test_loss: 0.470537:	
epoch: 214.000000:	train_loss: 0.498093:	test_loss: 0.483390:	
epoch: 215.000000:	train_loss: 0.504546:	test_loss: 0.478808:	
epoch: 216.000000:	train_loss: 0.508858:	test_loss: 0.489363:	
epoch: 217.000000:	train_loss: 0.509287:	test_loss: 0.479828:	
epoch: 218.000000:	train_loss: 0.494053:	test_loss: 0.483410:	
epoch: 219.000000:	train_loss: 0.503345:	test_loss: 0.480938:	
epoch: 220.000000:	train_loss: 0.490486:	test_loss: 0.477848:	
epoch: 221.000000:	train_loss: 0.501064:	test_loss: 0.483208:	
epoch: 222.000000:	train_loss: 0.502130:	test_loss: 0.476319:	
epoch: 223.000000:	train_loss: 0.499747:	test_loss: 0.477448:	
epoch: 224.000000:	train_loss: 0.509775:	test_loss: 0.479348:	
epoch: 225.000000:	train_loss: 0.502715:	test_loss: 0.480178:	
epoch: 226.000000:	train_loss: 0.504549:	test_loss: 0.479568:	
epoch: 227.000000:	train_loss: 0.495565:	test_loss: 0.481882:	
epoch: 228.000000:	train_loss: 0.501835:	test_loss: 0.480746:	
epoch: 229.000000:	train_loss: 0.497178:	test_loss: 0.482455:	
epoch: 230.000000:	train_loss: 0.497312:	test_loss: 0.472281:	
epoch: 231.000000:	train_loss: 0.486018:	test_loss: 0.473070:	
epoch: 232.000000:	train_loss: 0.496295:	test_loss: 0.482815:	
epoch: 233.000000:	train_loss: 0.493624:	test_loss: 0.481451:	
epoch: 234.000000:	train_loss: 0.498552:	test_loss: 0.479660:	
epoch: 235.000000:	train_loss: 0.499012:	test_loss: 0.473409:	
epoch: 236.000000:	train_loss: 0.513466:	test_loss: 0.474924:	
epoch: 237.000000:	train_loss: 0.501505:	test_loss: 0.475399:	
epoch: 238.000000:	train_loss: 0.489169:	test_loss: 0.478122:	
epoch: 239.000000:	train_loss: 0.492897:	test_loss: 0.470754:	
epoch: 240.000000:	train_loss: 0.502337:	test_loss: 0.468118:	
epoch: 241.000000:	train_loss: 0.494112:	test_loss: 0.476509:	
epoch: 242.000000:	train_loss: 0.482629:	test_loss: 0.500552:	
epoch: 243.000000:	train_loss: 0.504582:	test_loss: 0.469965:	
epoch: 244.000000:	train_loss: 0.497606:	test_loss: 0.470801:	
epoch: 245.000000:	train_loss: 0.503537:	test_loss: 0.477363:	
epoch: 246.000000:	train_loss: 0.503870:	test_loss: 0.484658:	
epoch: 247.000000:	train_loss: 0.491234:	test_loss: 0.512859:	
epoch: 248.000000:	train_loss: 0.489896:	test_loss: 0.470401:	
epoch: 249.000000:	train_loss: 0.494561:	test_loss: 0.485272:	
epoch: 250.000000:	train_loss: 0.493318:	test_loss: 0.479055:	
epoch: 251.000000:	train_loss: 0.491461:	test_loss: 0.467557:	
epoch: 252.000000:	train_loss: 0.499919:	test_loss: 0.473138:	
epoch: 253.000000:	train_loss: 0.491772:	test_loss: 0.470795:	
epoch: 254.000000:	train_loss: 0.486839:	test_loss: 0.466422:	
epoch: 255.000000:	train_loss: 0.500158:	test_loss: 0.468117:	
epoch: 256.000000:	train_loss: 0.485610:	test_loss: 0.471190:	
epoch: 257.000000:	train_loss: 0.498479:	test_loss: 0.475156:	
epoch: 258.000000:	train_loss: 0.498058:	test_loss: 0.477619:	
epoch: 259.000000:	train_loss: 0.494861:	test_loss: 0.466460:	
epoch: 260.000000:	train_loss: 0.498743:	test_loss: 0.475173:	
epoch: 261.000000:	train_loss: 0.499182:	test_loss: 0.465220:	
epoch: 262.000000:	train_loss: 0.489250:	test_loss: 0.465528:	
epoch: 263.000000:	train_loss: 0.487874:	test_loss: 0.469008:	
epoch: 264.000000:	train_loss: 0.484604:	test_loss: 0.469320:	
epoch: 265.000000:	train_loss: 0.497253:	test_loss: 0.472164:	
epoch: 266.000000:	train_loss: 0.494406:	test_loss: 0.463555:	
epoch: 267.000000:	train_loss: 0.493180:	test_loss: 0.473739:	
epoch: 268.000000:	train_loss: 0.491390:	test_loss: 0.472561:	
epoch: 269.000000:	train_loss: 0.499113:	test_loss: 0.491033:	
epoch: 270.000000:	train_loss: 0.503986:	test_loss: 0.466977:	
epoch: 271.000000:	train_loss: 0.486376:	test_loss: 0.474574:	
epoch: 272.000000:	train_loss: 0.483452:	test_loss: 0.480138:	
epoch: 273.000000:	train_loss: 0.504342:	test_loss: 0.474887:	
epoch: 274.000000:	train_loss: 0.492628:	test_loss: 0.468429:	
epoch: 275.000000:	train_loss: 0.486085:	test_loss: 0.472650:	
epoch: 276.000000:	train_loss: 0.486822:	test_loss: 0.476245:	
epoch: 277.000000:	train_loss: 0.499870:	test_loss: 0.475544:	
epoch: 278.000000:	train_loss: 0.489949:	test_loss: 0.481760:	
epoch: 279.000000:	train_loss: 0.486470:	test_loss: 0.472328:	
epoch: 280.000000:	train_loss: 0.490601:	test_loss: 0.477209:	
epoch: 281.000000:	train_loss: 0.491525:	test_loss: 0.466189:	
epoch: 282.000000:	train_loss: 0.493566:	test_loss: 0.482203:	
epoch: 283.000000:	train_loss: 0.486487:	test_loss: 0.474865:	
epoch: 284.000000:	train_loss: 0.493106:	test_loss: 0.470619:	
epoch: 285.000000:	train_loss: 0.489697:	test_loss: 0.484514:	
epoch: 286.000000:	train_loss: 0.488945:	test_loss: 0.463867:	
epoch: 287.000000:	train_loss: 0.496801:	test_loss: 0.468829:	
epoch: 288.000000:	train_loss: 0.489650:	test_loss: 0.461952:	
epoch: 289.000000:	train_loss: 0.492662:	test_loss: 0.471283:	
epoch: 290.000000:	train_loss: 0.489982:	test_loss: 0.491326:	
epoch: 291.000000:	train_loss: 0.492883:	test_loss: 0.467360:	
epoch: 292.000000:	train_loss: 0.501138:	test_loss: 0.471510:	
epoch: 293.000000:	train_loss: 0.500125:	test_loss: 0.454733:	
epoch: 294.000000:	train_loss: 0.489207:	test_loss: 0.464178:	
epoch: 295.000000:	train_loss: 0.490412:	test_loss: 0.470286:	
epoch: 296.000000:	train_loss: 0.484362:	test_loss: 0.466283:	
epoch: 297.000000:	train_loss: 0.481009:	test_loss: 0.468730:	
epoch: 298.000000:	train_loss: 0.489962:	test_loss: 0.467596:	
epoch: 299.000000:	train_loss: 0.489025:	test_loss: 0.460050:	
epoch: 300.000000:	train_loss: 0.488409:	test_loss: 0.463073:	
epoch: 301.000000:	train_loss: 0.489567:	test_loss: 0.474634:	
epoch: 302.000000:	train_loss: 0.491295:	test_loss: 0.468164:	
epoch: 303.000000:	train_loss: 0.488315:	test_loss: 0.473422:	
epoch: 304.000000:	train_loss: 0.485399:	test_loss: 0.478593:	
epoch: 305.000000:	train_loss: 0.495987:	test_loss: 0.462127:	
epoch: 306.000000:	train_loss: 0.489996:	test_loss: 0.466175:	
epoch: 307.000000:	train_loss: 0.494753:	test_loss: 0.473932:	
epoch: 308.000000:	train_loss: 0.490733:	test_loss: 0.463753:	
epoch: 309.000000:	train_loss: 0.490851:	test_loss: 0.462286:	
epoch: 310.000000:	train_loss: 0.491222:	test_loss: 0.459571:	
epoch: 311.000000:	train_loss: 0.485724:	test_loss: 0.470411:	
epoch: 312.000000:	train_loss: 0.503540:	test_loss: 0.482460:	
epoch: 313.000000:	train_loss: 0.485142:	test_loss: 0.460804:	
epoch: 314.000000:	train_loss: 0.497229:	test_loss: 0.474252:	
epoch: 315.000000:	train_loss: 0.493442:	test_loss: 0.466375:	
epoch: 316.000000:	train_loss: 0.486103:	test_loss: 0.460340:	
epoch: 317.000000:	train_loss: 0.488756:	test_loss: 0.469448:	
epoch: 318.000000:	train_loss: 0.494253:	test_loss: 0.466071:	
epoch: 319.000000:	train_loss: 0.497930:	test_loss: 0.462152:	
epoch: 320.000000:	train_loss: 0.489180:	test_loss: 0.467953:	
epoch: 321.000000:	train_loss: 0.491926:	test_loss: 0.553821:	
epoch: 322.000000:	train_loss: 0.487805:	test_loss: 0.458225:	
epoch: 323.000000:	train_loss: 0.487863:	test_loss: 0.470425:	
epoch: 324.000000:	train_loss: 0.491837:	test_loss: 0.462284:	
epoch: 325.000000:	train_loss: 0.493202:	test_loss: 0.461714:	
epoch: 326.000000:	train_loss: 0.491367:	test_loss: 0.464436:	
epoch: 327.000000:	train_loss: 0.485603:	test_loss: 0.469151:	
epoch: 328.000000:	train_loss: 0.499279:	test_loss: 0.475143:	
epoch: 329.000000:	train_loss: 0.488763:	test_loss: 0.462717:	
epoch: 330.000000:	train_loss: 0.483394:	test_loss: 0.462955:	
epoch: 331.000000:	train_loss: 0.493496:	test_loss: 0.463902:	
epoch: 332.000000:	train_loss: 0.486236:	test_loss: 0.469208:	
epoch: 333.000000:	train_loss: 0.485584:	test_loss: 0.462560:	
epoch: 334.000000:	train_loss: 0.495885:	test_loss: 0.461931:	
epoch: 335.000000:	train_loss: 0.485649:	test_loss: 0.466723:	
epoch: 336.000000:	train_loss: 0.488383:	test_loss: 0.472966:	
epoch: 337.000000:	train_loss: 0.480232:	test_loss: 0.485981:	
epoch: 338.000000:	train_loss: 0.493429:	test_loss: 0.467697:	
epoch: 339.000000:	train_loss: 0.475837:	test_loss: 0.461853:	
epoch: 340.000000:	train_loss: 0.492835:	test_loss: 0.459489:	
epoch: 341.000000:	train_loss: 0.471068:	test_loss: 0.462496:	
epoch: 342.000000:	train_loss: 0.495824:	test_loss: 0.456448:	
epoch: 343.000000:	train_loss: 0.491806:	test_loss: 0.474522:	
epoch: 344.000000:	train_loss: 0.485791:	test_loss: 0.480844:	
epoch: 345.000000:	train_loss: 0.488755:	test_loss: 0.477468:	
epoch: 346.000000:	train_loss: 0.478623:	test_loss: 0.457124:	
epoch: 347.000000:	train_loss: 0.489368:	test_loss: 0.484277:	
epoch: 348.000000:	train_loss: 0.493350:	test_loss: 0.471591:	
epoch: 349.000000:	train_loss: 0.484237:	test_loss: 0.465057:	
epoch: 350.000000:	train_loss: 0.489984:	test_loss: 0.476497:	
epoch: 351.000000:	train_loss: 0.495359:	test_loss: 0.466604:	
epoch: 352.000000:	train_loss: 0.489402:	test_loss: 0.461580:	
epoch: 353.000000:	train_loss: 0.481169:	test_loss: 0.468038:	
epoch: 354.000000:	train_loss: 0.484401:	test_loss: 0.464047:	
epoch: 355.000000:	train_loss: 0.490138:	test_loss: 0.454184:	
epoch: 356.000000:	train_loss: 0.492564:	test_loss: 0.469568:	
epoch: 357.000000:	train_loss: 0.483717:	test_loss: 0.464482:	
epoch: 358.000000:	train_loss: 0.484114:	test_loss: 0.455630:	
epoch: 359.000000:	train_loss: 0.485220:	test_loss: 0.464715:	
epoch: 360.000000:	train_loss: 0.491893:	test_loss: 0.463698:	
epoch: 361.000000:	train_loss: 0.491241:	test_loss: 0.468070:	
epoch: 362.000000:	train_loss: 0.489177:	test_loss: 0.467539:	
epoch: 363.000000:	train_loss: 0.493344:	test_loss: 0.467287:	
epoch: 364.000000:	train_loss: 0.480065:	test_loss: 0.467490:	
epoch: 365.000000:	train_loss: 0.489215:	test_loss: 0.464058:	
epoch: 366.000000:	train_loss: 0.480655:	test_loss: 0.469156:	
epoch: 367.000000:	train_loss: 0.486492:	test_loss: 0.475339:	
epoch: 368.000000:	train_loss: 0.485690:	test_loss: 0.458743:	
epoch: 369.000000:	train_loss: 0.475509:	test_loss: 0.467916:	
epoch: 370.000000:	train_loss: 0.491381:	test_loss: 0.478248:	
epoch: 371.000000:	train_loss: 0.483207:	test_loss: 0.482703:	
epoch: 372.000000:	train_loss: 0.485714:	test_loss: 0.466952:	
epoch: 373.000000:	train_loss: 0.480895:	test_loss: 0.463728:	
epoch: 374.000000:	train_loss: 0.490894:	test_loss: 0.472494:	
epoch: 375.000000:	train_loss: 0.483842:	test_loss: 0.468136:	
epoch: 376.000000:	train_loss: 0.488581:	test_loss: 0.462116:	
epoch: 377.000000:	train_loss: 0.494703:	test_loss: 0.459961:	
epoch: 378.000000:	train_loss: 0.478913:	test_loss: 0.456674:	
epoch: 379.000000:	train_loss: 0.495317:	test_loss: 0.457697:	
epoch: 380.000000:	train_loss: 0.481103:	test_loss: 0.462585:	
epoch: 381.000000:	train_loss: 0.483474:	test_loss: 0.462238:	
epoch: 382.000000:	train_loss: 0.478037:	test_loss: 0.468981:	
epoch: 383.000000:	train_loss: 0.482369:	test_loss: 0.460743:	
epoch: 384.000000:	train_loss: 0.487655:	test_loss: 0.482722:	
epoch: 385.000000:	train_loss: 0.487795:	test_loss: 0.459851:	
epoch: 386.000000:	train_loss: 0.484303:	test_loss: 0.471449:	
epoch: 387.000000:	train_loss: 0.480343:	test_loss: 0.462944:	
epoch: 388.000000:	train_loss: 0.482598:	test_loss: 0.461408:	
epoch: 389.000000:	train_loss: 0.491355:	test_loss: 0.470825:	
epoch: 390.000000:	train_loss: 0.479960:	test_loss: 0.461720:	
epoch: 391.000000:	train_loss: 0.480735:	test_loss: 0.470286:	
epoch: 392.000000:	train_loss: 0.481237:	test_loss: 0.467222:	
epoch: 393.000000:	train_loss: 0.488743:	test_loss: 0.464937:	
epoch: 394.000000:	train_loss: 0.484819:	test_loss: 0.459489:	
epoch: 395.000000:	train_loss: 0.486045:	test_loss: 0.457330:	
epoch: 396.000000:	train_loss: 0.477404:	test_loss: 0.465623:	
epoch: 397.000000:	train_loss: 0.487357:	test_loss: 0.462789:	
epoch: 398.000000:	train_loss: 0.480496:	test_loss: 0.463943:	
epoch: 399.000000:	train_loss: 0.484511:	test_loss: 0.471613:	
epoch: 400.000000:	train_loss: 0.473683:	test_loss: 0.462334:	
epoch: 401.000000:	train_loss: 0.491270:	test_loss: 0.458487:	
epoch: 402.000000:	train_loss: 0.488830:	test_loss: 0.490372:	
epoch: 403.000000:	train_loss: 0.498488:	test_loss: 0.460633:	
epoch: 404.000000:	train_loss: 0.474232:	test_loss: 0.494772:	
epoch: 405.000000:	train_loss: 0.485948:	test_loss: 0.453840:	
epoch: 406.000000:	train_loss: 0.478661:	test_loss: 0.457421:	
epoch: 407.000000:	train_loss: 0.490689:	test_loss: 0.458297:	
epoch: 408.000000:	train_loss: 0.476328:	test_loss: 0.464663:	
epoch: 409.000000:	train_loss: 0.484589:	test_loss: 0.479129:	
epoch: 410.000000:	train_loss: 0.491951:	test_loss: 0.458705:	
epoch: 411.000000:	train_loss: 0.475002:	test_loss: 0.461588:	
epoch: 412.000000:	train_loss: 0.487056:	test_loss: 0.463164:	
epoch: 413.000000:	train_loss: 0.480928:	test_loss: 0.461062:	
epoch: 414.000000:	train_loss: 0.475416:	test_loss: 0.458339:	
epoch: 415.000000:	train_loss: 0.476629:	test_loss: 0.458162:	
epoch: 416.000000:	train_loss: 0.486808:	test_loss: 0.553989:	
epoch: 417.000000:	train_loss: 0.487011:	test_loss: 0.462272:	
epoch: 418.000000:	train_loss: 0.481268:	test_loss: 0.467214:	
epoch: 419.000000:	train_loss: 0.486062:	test_loss: 0.463730:	
epoch: 420.000000:	train_loss: 0.477452:	test_loss: 0.460634:	
epoch: 421.000000:	train_loss: 0.486813:	test_loss: 0.469071:	
epoch: 422.000000:	train_loss: 0.482697:	test_loss: 0.470205:	
epoch: 423.000000:	train_loss: 0.492065:	test_loss: 0.464565:	
epoch: 424.000000:	train_loss: 0.478812:	test_loss: 0.467870:	
epoch: 425.000000:	train_loss: 0.476531:	test_loss: 0.458060:	
epoch: 426.000000:	train_loss: 0.482385:	test_loss: 0.460352:	
epoch: 427.000000:	train_loss: 0.484006:	test_loss: 0.458847:	
epoch: 428.000000:	train_loss: 0.474244:	test_loss: 0.458137:	
epoch: 429.000000:	train_loss: 0.483211:	test_loss: 0.459425:	
epoch: 430.000000:	train_loss: 0.486116:	test_loss: 0.463292:	
epoch: 431.000000:	train_loss: 0.478735:	test_loss: 0.455708:	
epoch: 432.000000:	train_loss: 0.483739:	test_loss: 0.466325:	
epoch: 433.000000:	train_loss: 0.478907:	test_loss: 0.494282:	
epoch: 434.000000:	train_loss: 0.477253:	test_loss: 0.470256:	
epoch: 435.000000:	train_loss: 0.480086:	test_loss: 0.461178:	
epoch: 436.000000:	train_loss: 0.485466:	test_loss: 0.460004:	
epoch: 437.000000:	train_loss: 0.484879:	test_loss: 0.464499:	
epoch: 438.000000:	train_loss: 0.487086:	test_loss: 0.473549:	
epoch: 439.000000:	train_loss: 0.487229:	test_loss: 0.462706:	
epoch: 440.000000:	train_loss: 0.475019:	test_loss: 0.463771:	
epoch: 441.000000:	train_loss: 0.488319:	test_loss: 0.472252:	
epoch: 442.000000:	train_loss: 0.477291:	test_loss: 0.458818:	
epoch: 443.000000:	train_loss: 0.482720:	test_loss: 0.465210:	
epoch: 444.000000:	train_loss: 0.482812:	test_loss: 0.468034:	
epoch: 445.000000:	train_loss: 0.478731:	test_loss: 0.463561:	
epoch: 446.000000:	train_loss: 0.487031:	test_loss: 0.462665:	
epoch: 447.000000:	train_loss: 0.481187:	test_loss: 0.454810:	
epoch: 448.000000:	train_loss: 0.472073:	test_loss: 0.481960:	
epoch: 449.000000:	train_loss: 0.487606:	test_loss: 0.469774:	
epoch: 450.000000:	train_loss: 0.482638:	test_loss: 0.463940:	
epoch: 451.000000:	train_loss: 0.485638:	test_loss: 0.465497:	
epoch: 452.000000:	train_loss: 0.484285:	test_loss: 0.486347:	
epoch: 453.000000:	train_loss: 0.481988:	test_loss: 0.456687:	
epoch: 454.000000:	train_loss: 0.483432:	test_loss: 0.460267:	
epoch: 455.000000:	train_loss: 0.480826:	test_loss: 0.456771:	
epoch: 456.000000:	train_loss: 0.479795:	test_loss: 0.470063:	
epoch: 457.000000:	train_loss: 0.480636:	test_loss: 0.463329:	
epoch: 458.000000:	train_loss: 0.479326:	test_loss: 0.460567:	
epoch: 459.000000:	train_loss: 0.476484:	test_loss: 0.461762:	
epoch: 460.000000:	train_loss: 0.480889:	test_loss: 0.456779:	
epoch: 461.000000:	train_loss: 0.498182:	test_loss: 0.457169:	
epoch: 462.000000:	train_loss: 0.492264:	test_loss: 0.461619:	
epoch: 463.000000:	train_loss: 0.501957:	test_loss: 0.464081:	
epoch: 464.000000:	train_loss: 0.480158:	test_loss: 0.457837:	
epoch: 465.000000:	train_loss: 0.487647:	test_loss: 0.462451:	
epoch: 466.000000:	train_loss: 0.492284:	test_loss: 0.464625:	
epoch: 467.000000:	train_loss: 0.494271:	test_loss: 0.460727:	
epoch: 468.000000:	train_loss: 0.483164:	test_loss: 0.463268:	
epoch: 469.000000:	train_loss: 0.480226:	test_loss: 0.467513:	
epoch: 470.000000:	train_loss: 0.476800:	test_loss: 0.473097:	
epoch: 471.000000:	train_loss: 0.488667:	test_loss: 0.459183:	
epoch: 472.000000:	train_loss: 0.482358:	test_loss: 0.459710:	
epoch: 473.000000:	train_loss: 0.485911:	test_loss: 0.457758:	
epoch: 474.000000:	train_loss: 0.484167:	test_loss: 0.456967:	
epoch: 475.000000:	train_loss: 0.486865:	test_loss: 0.467037:	
epoch: 476.000000:	train_loss: 0.494703:	test_loss: 0.461364:	
epoch: 477.000000:	train_loss: 0.483501:	test_loss: 0.459427:	
epoch: 478.000000:	train_loss: 0.477044:	test_loss: 0.458949:	
epoch: 479.000000:	train_loss: 0.482201:	test_loss: 0.458372:	
epoch: 480.000000:	train_loss: 0.482449:	test_loss: 0.460407:	
epoch: 481.000000:	train_loss: 0.482243:	test_loss: 0.456202:	
epoch: 482.000000:	train_loss: 0.486435:	test_loss: 0.463611:	
epoch: 483.000000:	train_loss: 0.475794:	test_loss: 0.473617:	
epoch: 484.000000:	train_loss: 0.489324:	test_loss: 0.452124:	
epoch: 485.000000:	train_loss: 0.484391:	test_loss: 0.462498:	
epoch: 486.000000:	train_loss: 0.477046:	test_loss: 0.463887:	
epoch: 487.000000:	train_loss: 0.480358:	test_loss: 0.464753:	
epoch: 488.000000:	train_loss: 0.487594:	test_loss: 0.464485:	
epoch: 489.000000:	train_loss: 0.487098:	test_loss: 0.456554:	
epoch: 490.000000:	train_loss: 0.479263:	test_loss: 0.463084:	
epoch: 491.000000:	train_loss: 0.489035:	test_loss: 0.457377:	
epoch: 492.000000:	train_loss: 0.489963:	test_loss: 0.452792:	
epoch: 493.000000:	train_loss: 0.478760:	test_loss: 0.464898:	
epoch: 494.000000:	train_loss: 0.481525:	test_loss: 0.458368:	
epoch: 495.000000:	train_loss: 0.480082:	test_loss: 0.455489:	
epoch: 496.000000:	train_loss: 0.485263:	test_loss: 0.461804:	
epoch: 497.000000:	train_loss: 0.497050:	test_loss: 0.465812:	
epoch: 498.000000:	train_loss: 0.484828:	test_loss: 0.464521:	
epoch: 499.000000:	train_loss: 0.483719:	test_loss: 0.463209:	
