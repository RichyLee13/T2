epoch: 0.000000:	train_loss: 0.999628:	test_loss: 2.124798:	
epoch: 1.000000:	train_loss: 1.426262:	test_loss: 1.423935:	
epoch: 2.000000:	train_loss: 1.362587:	test_loss: 1.423935:	
epoch: 3.000000:	train_loss: 1.353457:	test_loss: 1.423935:	
epoch: 4.000000:	train_loss: 1.344006:	test_loss: 1.423935:	
epoch: 5.000000:	train_loss: 1.348986:	test_loss: 1.423935:	
epoch: 6.000000:	train_loss: 1.349121:	test_loss: 1.423935:	
epoch: 7.000000:	train_loss: 1.349613:	test_loss: 1.423935:	
epoch: 8.000000:	train_loss: 1.348364:	test_loss: 1.423935:	
epoch: 9.000000:	train_loss: 1.347415:	test_loss: 1.423935:	
epoch: 10.000000:	train_loss: 1.342706:	test_loss: 1.423935:	
epoch: 11.000000:	train_loss: 1.346172:	test_loss: 1.423935:	
epoch: 12.000000:	train_loss: 1.341459:	test_loss: 1.423935:	
epoch: 13.000000:	train_loss: 1.344471:	test_loss: 1.423935:	
epoch: 14.000000:	train_loss: 1.348832:	test_loss: 1.423935:	
epoch: 15.000000:	train_loss: 1.345738:	test_loss: 1.423935:	
epoch: 16.000000:	train_loss: 1.336781:	test_loss: 1.423935:	
epoch: 17.000000:	train_loss: 1.344894:	test_loss: 1.423935:	
epoch: 18.000000:	train_loss: 1.343167:	test_loss: 1.423935:	
epoch: 19.000000:	train_loss: 1.345026:	test_loss: 1.423935:	
epoch: 20.000000:	train_loss: 1.343176:	test_loss: 1.423935:	
epoch: 21.000000:	train_loss: 1.344264:	test_loss: 1.423935:	
epoch: 22.000000:	train_loss: 1.338796:	test_loss: 1.423935:	
epoch: 23.000000:	train_loss: 1.342581:	test_loss: 1.423935:	
epoch: 24.000000:	train_loss: 1.342649:	test_loss: 1.423935:	
epoch: 25.000000:	train_loss: 1.345501:	test_loss: 1.423935:	
epoch: 26.000000:	train_loss: 1.339163:	test_loss: 1.423935:	
epoch: 27.000000:	train_loss: 1.341731:	test_loss: 1.423935:	
epoch: 28.000000:	train_loss: 1.339272:	test_loss: 1.423935:	
epoch: 29.000000:	train_loss: 1.342581:	test_loss: 1.423935:	
epoch: 30.000000:	train_loss: 1.338695:	test_loss: 1.423935:	
epoch: 31.000000:	train_loss: 1.335523:	test_loss: 1.423935:	
epoch: 32.000000:	train_loss: 1.341130:	test_loss: 1.423935:	
epoch: 33.000000:	train_loss: 1.343938:	test_loss: 1.423935:	
epoch: 34.000000:	train_loss: 1.334447:	test_loss: 1.423935:	
epoch: 35.000000:	train_loss: 1.343615:	test_loss: 1.423935:	
epoch: 36.000000:	train_loss: 1.340166:	test_loss: 1.423935:	
epoch: 37.000000:	train_loss: 1.342195:	test_loss: 1.423935:	
epoch: 38.000000:	train_loss: 1.340030:	test_loss: 1.423935:	
epoch: 39.000000:	train_loss: 1.339493:	test_loss: 1.423935:	
epoch: 40.000000:	train_loss: 1.338541:	test_loss: 1.423935:	
epoch: 41.000000:	train_loss: 1.342390:	test_loss: 1.423935:	
epoch: 42.000000:	train_loss: 1.339421:	test_loss: 1.423935:	
epoch: 43.000000:	train_loss: 1.343118:	test_loss: 1.423935:	
epoch: 44.000000:	train_loss: 1.338211:	test_loss: 1.423935:	
epoch: 45.000000:	train_loss: 1.333457:	test_loss: 1.423935:	
epoch: 46.000000:	train_loss: 1.337659:	test_loss: 1.423935:	
epoch: 47.000000:	train_loss: 1.340687:	test_loss: 1.423935:	
epoch: 48.000000:	train_loss: 1.343596:	test_loss: 1.423935:	
epoch: 49.000000:	train_loss: 1.335947:	test_loss: 1.423935:	
epoch: 50.000000:	train_loss: 1.339989:	test_loss: 1.423935:	
epoch: 51.000000:	train_loss: 1.335651:	test_loss: 1.423935:	
epoch: 52.000000:	train_loss: 1.335779:	test_loss: 1.423935:	
epoch: 53.000000:	train_loss: 1.338084:	test_loss: 1.423935:	
epoch: 54.000000:	train_loss: 1.336831:	test_loss: 1.423935:	
epoch: 55.000000:	train_loss: 1.340764:	test_loss: 1.423935:	
epoch: 56.000000:	train_loss: 1.341648:	test_loss: 1.423935:	
epoch: 57.000000:	train_loss: 1.332706:	test_loss: 1.423935:	
epoch: 58.000000:	train_loss: 1.336127:	test_loss: 1.423935:	
epoch: 59.000000:	train_loss: 1.331787:	test_loss: 1.423935:	
epoch: 60.000000:	train_loss: 1.340169:	test_loss: 1.423935:	
epoch: 61.000000:	train_loss: 1.339018:	test_loss: 1.423935:	
epoch: 62.000000:	train_loss: 1.338740:	test_loss: 1.423935:	
epoch: 63.000000:	train_loss: 1.333582:	test_loss: 1.423935:	
epoch: 64.000000:	train_loss: 1.338762:	test_loss: 1.423935:	
epoch: 65.000000:	train_loss: 1.337758:	test_loss: 1.423935:	
epoch: 66.000000:	train_loss: 1.336403:	test_loss: 1.423935:	
epoch: 67.000000:	train_loss: 1.332888:	test_loss: 1.423935:	
epoch: 68.000000:	train_loss: 1.331578:	test_loss: 1.423935:	
epoch: 69.000000:	train_loss: 1.337298:	test_loss: 1.423935:	
epoch: 70.000000:	train_loss: 1.332862:	test_loss: 1.423935:	
epoch: 71.000000:	train_loss: 1.334323:	test_loss: 1.423935:	
epoch: 72.000000:	train_loss: 1.334705:	test_loss: 1.423935:	
epoch: 73.000000:	train_loss: 1.335666:	test_loss: 1.423935:	
epoch: 74.000000:	train_loss: 1.334383:	test_loss: 1.423935:	
epoch: 75.000000:	train_loss: 1.335814:	test_loss: 1.423935:	
epoch: 76.000000:	train_loss: 1.329580:	test_loss: 1.423935:	
epoch: 77.000000:	train_loss: 1.333742:	test_loss: 1.423935:	
epoch: 78.000000:	train_loss: 1.330680:	test_loss: 1.423935:	
epoch: 79.000000:	train_loss: 1.330984:	test_loss: 1.423935:	
epoch: 80.000000:	train_loss: 1.331224:	test_loss: 1.423935:	
epoch: 81.000000:	train_loss: 1.329367:	test_loss: 1.423935:	
epoch: 82.000000:	train_loss: 1.333748:	test_loss: 1.423935:	
epoch: 83.000000:	train_loss: 1.331183:	test_loss: 1.423935:	
epoch: 84.000000:	train_loss: 1.331469:	test_loss: 1.423935:	
epoch: 85.000000:	train_loss: 1.329928:	test_loss: 1.423935:	
epoch: 86.000000:	train_loss: 1.327548:	test_loss: 1.423935:	
epoch: 87.000000:	train_loss: 1.324258:	test_loss: 1.423935:	
epoch: 88.000000:	train_loss: 1.321694:	test_loss: 1.423935:	
epoch: 89.000000:	train_loss: 1.324189:	test_loss: 1.423935:	
epoch: 90.000000:	train_loss: 1.330534:	test_loss: 1.423935:	
epoch: 91.000000:	train_loss: 1.329392:	test_loss: 1.423935:	
epoch: 92.000000:	train_loss: 1.330142:	test_loss: 1.423935:	
epoch: 93.000000:	train_loss: 1.323562:	test_loss: 1.423935:	
epoch: 94.000000:	train_loss: 1.325405:	test_loss: 1.423935:	
epoch: 95.000000:	train_loss: 1.322712:	test_loss: 1.423935:	
epoch: 96.000000:	train_loss: 1.327932:	test_loss: 1.423935:	
epoch: 97.000000:	train_loss: 1.323440:	test_loss: 1.423935:	
epoch: 98.000000:	train_loss: 1.326154:	test_loss: 1.423935:	
epoch: 99.000000:	train_loss: 1.321732:	test_loss: 1.423935:	
epoch: 100.000000:	train_loss: 1.319149:	test_loss: 1.423935:	
epoch: 101.000000:	train_loss: 1.326563:	test_loss: 1.423935:	
epoch: 102.000000:	train_loss: 1.317997:	test_loss: 1.423935:	
epoch: 103.000000:	train_loss: 1.318143:	test_loss: 1.423935:	
epoch: 104.000000:	train_loss: 1.320646:	test_loss: 1.423935:	
epoch: 105.000000:	train_loss: 1.321631:	test_loss: 1.423935:	
epoch: 106.000000:	train_loss: 1.315892:	test_loss: 1.423918:	
epoch: 107.000000:	train_loss: 1.309402:	test_loss: 1.423926:	
epoch: 108.000000:	train_loss: 1.299218:	test_loss: 1.423677:	
epoch: 109.000000:	train_loss: 1.291875:	test_loss: 1.315355:	
epoch: 110.000000:	train_loss: 1.281682:	test_loss: 1.268908:	
epoch: 111.000000:	train_loss: 1.268693:	test_loss: 1.280802:	
epoch: 112.000000:	train_loss: 1.266844:	test_loss: 1.295837:	
epoch: 113.000000:	train_loss: 1.265043:	test_loss: 1.259809:	
epoch: 114.000000:	train_loss: 1.264044:	test_loss: 1.246327:	
epoch: 115.000000:	train_loss: 1.263967:	test_loss: 1.258224:	
epoch: 116.000000:	train_loss: 1.256148:	test_loss: 1.287655:	
epoch: 117.000000:	train_loss: 1.257521:	test_loss: 1.248311:	
epoch: 118.000000:	train_loss: 1.256894:	test_loss: 1.257680:	
epoch: 119.000000:	train_loss: 1.255469:	test_loss: 1.247999:	
epoch: 120.000000:	train_loss: 1.247042:	test_loss: 1.235475:	
epoch: 121.000000:	train_loss: 1.250799:	test_loss: 1.263009:	
epoch: 122.000000:	train_loss: 1.248822:	test_loss: 1.236684:	
epoch: 123.000000:	train_loss: 1.249452:	test_loss: 1.222432:	
epoch: 124.000000:	train_loss: 1.249256:	test_loss: 1.237689:	
epoch: 125.000000:	train_loss: 1.242954:	test_loss: 1.229233:	
epoch: 126.000000:	train_loss: 1.240767:	test_loss: 1.226428:	
epoch: 127.000000:	train_loss: 1.237007:	test_loss: 1.217706:	
epoch: 128.000000:	train_loss: 1.238729:	test_loss: 1.226057:	
epoch: 129.000000:	train_loss: 1.237023:	test_loss: 1.220365:	
epoch: 130.000000:	train_loss: 1.235981:	test_loss: 1.226154:	
epoch: 131.000000:	train_loss: 1.237584:	test_loss: 1.205966:	
epoch: 132.000000:	train_loss: 1.232260:	test_loss: 1.205277:	
epoch: 133.000000:	train_loss: 1.223622:	test_loss: 1.200064:	
epoch: 134.000000:	train_loss: 1.214734:	test_loss: 1.207294:	
epoch: 135.000000:	train_loss: 1.196919:	test_loss: 1.154250:	
epoch: 136.000000:	train_loss: 1.195513:	test_loss: 1.124162:	
epoch: 137.000000:	train_loss: 1.192753:	test_loss: 1.121599:	
epoch: 138.000000:	train_loss: 1.188501:	test_loss: 1.137297:	
epoch: 139.000000:	train_loss: 1.185867:	test_loss: 1.138098:	
epoch: 140.000000:	train_loss: 1.180679:	test_loss: 1.112253:	
epoch: 141.000000:	train_loss: 1.178891:	test_loss: 1.097723:	
epoch: 142.000000:	train_loss: 1.177602:	test_loss: 1.141713:	
epoch: 143.000000:	train_loss: 1.178118:	test_loss: 1.111696:	
epoch: 144.000000:	train_loss: 1.170400:	test_loss: 1.096602:	
epoch: 145.000000:	train_loss: 1.172000:	test_loss: 1.095827:	
epoch: 146.000000:	train_loss: 1.170735:	test_loss: 1.117309:	
epoch: 147.000000:	train_loss: 1.171839:	test_loss: 1.089836:	
epoch: 148.000000:	train_loss: 1.165466:	test_loss: 1.080873:	
epoch: 149.000000:	train_loss: 1.164378:	test_loss: 1.077607:	
epoch: 150.000000:	train_loss: 1.166061:	test_loss: 1.072308:	
epoch: 151.000000:	train_loss: 1.161659:	test_loss: 1.065750:	
epoch: 152.000000:	train_loss: 1.161690:	test_loss: 1.101330:	
epoch: 153.000000:	train_loss: 1.157955:	test_loss: 1.053336:	
epoch: 154.000000:	train_loss: 1.153346:	test_loss: 1.039317:	
epoch: 155.000000:	train_loss: 1.159685:	test_loss: 1.049097:	
epoch: 156.000000:	train_loss: 1.152039:	test_loss: 1.038692:	
epoch: 157.000000:	train_loss: 1.148138:	test_loss: 1.032248:	
epoch: 158.000000:	train_loss: 1.148181:	test_loss: 1.027772:	
epoch: 159.000000:	train_loss: 1.146340:	test_loss: 1.098652:	
epoch: 160.000000:	train_loss: 1.149997:	test_loss: 1.060934:	
epoch: 161.000000:	train_loss: 1.143305:	test_loss: 1.011007:	
epoch: 162.000000:	train_loss: 1.144577:	test_loss: 1.023140:	
epoch: 163.000000:	train_loss: 1.139811:	test_loss: 1.005082:	
epoch: 164.000000:	train_loss: 1.141141:	test_loss: 1.019663:	
epoch: 165.000000:	train_loss: 1.139702:	test_loss: 1.005241:	
epoch: 166.000000:	train_loss: 1.140798:	test_loss: 1.003758:	
epoch: 167.000000:	train_loss: 1.135812:	test_loss: 1.010479:	
epoch: 168.000000:	train_loss: 1.137928:	test_loss: 1.007610:	
epoch: 169.000000:	train_loss: 1.134738:	test_loss: 0.987925:	
epoch: 170.000000:	train_loss: 1.131979:	test_loss: 0.987583:	
epoch: 171.000000:	train_loss: 1.135772:	test_loss: 1.011559:	
epoch: 172.000000:	train_loss: 1.136342:	test_loss: 1.007854:	
epoch: 173.000000:	train_loss: 1.135044:	test_loss: 1.072831:	
epoch: 174.000000:	train_loss: 1.132450:	test_loss: 0.977180:	
epoch: 175.000000:	train_loss: 1.132758:	test_loss: 0.998828:	
epoch: 176.000000:	train_loss: 1.130211:	test_loss: 1.034787:	
epoch: 177.000000:	train_loss: 1.131621:	test_loss: 0.996456:	
epoch: 178.000000:	train_loss: 1.128413:	test_loss: 0.990866:	
epoch: 179.000000:	train_loss: 1.126286:	test_loss: 0.995267:	
epoch: 180.000000:	train_loss: 1.125807:	test_loss: 0.983119:	
epoch: 181.000000:	train_loss: 1.126906:	test_loss: 0.973813:	
epoch: 182.000000:	train_loss: 1.122363:	test_loss: 0.976482:	
epoch: 183.000000:	train_loss: 1.124877:	test_loss: 0.992869:	
epoch: 184.000000:	train_loss: 1.125081:	test_loss: 0.986188:	
epoch: 185.000000:	train_loss: 1.123404:	test_loss: 1.001474:	
epoch: 186.000000:	train_loss: 1.120209:	test_loss: 1.003801:	
epoch: 187.000000:	train_loss: 1.122030:	test_loss: 0.978139:	
epoch: 188.000000:	train_loss: 1.125108:	test_loss: 0.970612:	
epoch: 189.000000:	train_loss: 1.118481:	test_loss: 0.958143:	
epoch: 190.000000:	train_loss: 1.120695:	test_loss: 0.954968:	
epoch: 191.000000:	train_loss: 1.120554:	test_loss: 0.981240:	
epoch: 192.000000:	train_loss: 1.124423:	test_loss: 0.973520:	
epoch: 193.000000:	train_loss: 1.119309:	test_loss: 0.981435:	
epoch: 194.000000:	train_loss: 1.117746:	test_loss: 0.965163:	
epoch: 195.000000:	train_loss: 1.120734:	test_loss: 0.987816:	
epoch: 196.000000:	train_loss: 1.111474:	test_loss: 0.978112:	
epoch: 197.000000:	train_loss: 1.116317:	test_loss: 0.988383:	
epoch: 198.000000:	train_loss: 1.118088:	test_loss: 0.960881:	
epoch: 199.000000:	train_loss: 1.116324:	test_loss: 0.958310:	
epoch: 200.000000:	train_loss: 1.116072:	test_loss: 0.977169:	
epoch: 201.000000:	train_loss: 1.114340:	test_loss: 0.966384:	
epoch: 202.000000:	train_loss: 1.115632:	test_loss: 0.954990:	
epoch: 203.000000:	train_loss: 1.117816:	test_loss: 0.978655:	
epoch: 204.000000:	train_loss: 1.116012:	test_loss: 0.983428:	
epoch: 205.000000:	train_loss: 1.113333:	test_loss: 0.966953:	
epoch: 206.000000:	train_loss: 1.117725:	test_loss: 0.952350:	
epoch: 207.000000:	train_loss: 1.113097:	test_loss: 0.966710:	
epoch: 208.000000:	train_loss: 1.109060:	test_loss: 0.965383:	
epoch: 209.000000:	train_loss: 1.108062:	test_loss: 0.998352:	
epoch: 210.000000:	train_loss: 1.110457:	test_loss: 0.957841:	
epoch: 211.000000:	train_loss: 1.112051:	test_loss: 0.962488:	
epoch: 212.000000:	train_loss: 1.112013:	test_loss: 0.985205:	
epoch: 213.000000:	train_loss: 1.112974:	test_loss: 0.967341:	
epoch: 214.000000:	train_loss: 1.110713:	test_loss: 0.942431:	
epoch: 215.000000:	train_loss: 1.115505:	test_loss: 0.954678:	
epoch: 216.000000:	train_loss: 1.110150:	test_loss: 0.944243:	
epoch: 217.000000:	train_loss: 1.107800:	test_loss: 0.957362:	
epoch: 218.000000:	train_loss: 1.109246:	test_loss: 0.943737:	
epoch: 219.000000:	train_loss: 1.104421:	test_loss: 0.955599:	
epoch: 220.000000:	train_loss: 1.105331:	test_loss: 0.957984:	
epoch: 221.000000:	train_loss: 1.109308:	test_loss: 0.942104:	
epoch: 222.000000:	train_loss: 1.103908:	test_loss: 0.936176:	
epoch: 223.000000:	train_loss: 1.104573:	test_loss: 0.960161:	
epoch: 224.000000:	train_loss: 1.105339:	test_loss: 0.969060:	
epoch: 225.000000:	train_loss: 1.109156:	test_loss: 0.942326:	
epoch: 226.000000:	train_loss: 1.104694:	test_loss: 0.959365:	
epoch: 227.000000:	train_loss: 1.105715:	test_loss: 0.946380:	
epoch: 228.000000:	train_loss: 1.103056:	test_loss: 0.939818:	
epoch: 229.000000:	train_loss: 1.104562:	test_loss: 0.939194:	
epoch: 230.000000:	train_loss: 1.105630:	test_loss: 0.951094:	
epoch: 231.000000:	train_loss: 1.106627:	test_loss: 0.937211:	
epoch: 232.000000:	train_loss: 1.102684:	test_loss: 0.937268:	
epoch: 233.000000:	train_loss: 1.103717:	test_loss: 0.964698:	
epoch: 234.000000:	train_loss: 1.106524:	test_loss: 0.956637:	
epoch: 235.000000:	train_loss: 1.105295:	test_loss: 0.942063:	
epoch: 236.000000:	train_loss: 1.103485:	test_loss: 0.953713:	
epoch: 237.000000:	train_loss: 1.103100:	test_loss: 0.939519:	
epoch: 238.000000:	train_loss: 1.101031:	test_loss: 0.960406:	
epoch: 239.000000:	train_loss: 1.103920:	test_loss: 0.941122:	
epoch: 240.000000:	train_loss: 1.105329:	test_loss: 0.931322:	
epoch: 241.000000:	train_loss: 1.100947:	test_loss: 0.938678:	
epoch: 242.000000:	train_loss: 1.103426:	test_loss: 0.940466:	
epoch: 243.000000:	train_loss: 1.094078:	test_loss: 0.928898:	
epoch: 244.000000:	train_loss: 1.101664:	test_loss: 0.938604:	
epoch: 245.000000:	train_loss: 1.096307:	test_loss: 0.957021:	
epoch: 246.000000:	train_loss: 1.098327:	test_loss: 0.952090:	
epoch: 247.000000:	train_loss: 1.096878:	test_loss: 0.930203:	
epoch: 248.000000:	train_loss: 1.096536:	test_loss: 0.931715:	
epoch: 249.000000:	train_loss: 1.101294:	test_loss: 0.979526:	
epoch: 250.000000:	train_loss: 1.099755:	test_loss: 0.931000:	
epoch: 251.000000:	train_loss: 1.098826:	test_loss: 0.950561:	
epoch: 252.000000:	train_loss: 1.093500:	test_loss: 0.939000:	
epoch: 253.000000:	train_loss: 1.094992:	test_loss: 0.938471:	
epoch: 254.000000:	train_loss: 1.100953:	test_loss: 0.926520:	
epoch: 255.000000:	train_loss: 1.096426:	test_loss: 0.933136:	
epoch: 256.000000:	train_loss: 1.092738:	test_loss: 0.930605:	
epoch: 257.000000:	train_loss: 1.096604:	test_loss: 0.925024:	
epoch: 258.000000:	train_loss: 1.093522:	test_loss: 0.930156:	
epoch: 259.000000:	train_loss: 1.099182:	test_loss: 0.940989:	
epoch: 260.000000:	train_loss: 1.094634:	test_loss: 0.927810:	
epoch: 261.000000:	train_loss: 1.098156:	test_loss: 0.936840:	
epoch: 262.000000:	train_loss: 1.097042:	test_loss: 0.928653:	
epoch: 263.000000:	train_loss: 1.093890:	test_loss: 0.937317:	
epoch: 264.000000:	train_loss: 1.093309:	test_loss: 0.938349:	
epoch: 265.000000:	train_loss: 1.096828:	test_loss: 0.929816:	
epoch: 266.000000:	train_loss: 1.100191:	test_loss: 0.933815:	
epoch: 267.000000:	train_loss: 1.093835:	test_loss: 0.923054:	
epoch: 268.000000:	train_loss: 1.096565:	test_loss: 0.932933:	
epoch: 269.000000:	train_loss: 1.093585:	test_loss: 0.942608:	
epoch: 270.000000:	train_loss: 1.093183:	test_loss: 0.928449:	
epoch: 271.000000:	train_loss: 1.094811:	test_loss: 0.922873:	
epoch: 272.000000:	train_loss: 1.091132:	test_loss: 0.934117:	
epoch: 273.000000:	train_loss: 1.092303:	test_loss: 0.924225:	
epoch: 274.000000:	train_loss: 1.094617:	test_loss: 0.919386:	
epoch: 275.000000:	train_loss: 1.092636:	test_loss: 0.927698:	
epoch: 276.000000:	train_loss: 1.090163:	test_loss: 0.925708:	
epoch: 277.000000:	train_loss: 1.092056:	test_loss: 0.922417:	
epoch: 278.000000:	train_loss: 1.094175:	test_loss: 0.936776:	
epoch: 279.000000:	train_loss: 1.096768:	test_loss: 0.925305:	
epoch: 280.000000:	train_loss: 1.086593:	test_loss: 0.932321:	
epoch: 281.000000:	train_loss: 1.093003:	test_loss: 0.928215:	
epoch: 282.000000:	train_loss: 1.093786:	test_loss: 0.952220:	
epoch: 283.000000:	train_loss: 1.090689:	test_loss: 0.959704:	
epoch: 284.000000:	train_loss: 1.093923:	test_loss: 0.950082:	
epoch: 285.000000:	train_loss: 1.090167:	test_loss: 0.931690:	
epoch: 286.000000:	train_loss: 1.093064:	test_loss: 0.927854:	
epoch: 287.000000:	train_loss: 1.088343:	test_loss: 0.916478:	
epoch: 288.000000:	train_loss: 1.086429:	test_loss: 0.949451:	
epoch: 289.000000:	train_loss: 1.091742:	test_loss: 0.929127:	
epoch: 290.000000:	train_loss: 1.087912:	test_loss: 0.927116:	
epoch: 291.000000:	train_loss: 1.089999:	test_loss: 0.924379:	
epoch: 292.000000:	train_loss: 1.089256:	test_loss: 0.919545:	
epoch: 293.000000:	train_loss: 1.088883:	test_loss: 0.918962:	
epoch: 294.000000:	train_loss: 1.089177:	test_loss: 0.925481:	
epoch: 295.000000:	train_loss: 1.092465:	test_loss: 0.919769:	
epoch: 296.000000:	train_loss: 1.086088:	test_loss: 0.933515:	
epoch: 297.000000:	train_loss: 1.086370:	test_loss: 0.924708:	
epoch: 298.000000:	train_loss: 1.083083:	test_loss: 0.913253:	
epoch: 299.000000:	train_loss: 1.087829:	test_loss: 0.921049:	
epoch: 300.000000:	train_loss: 1.090218:	test_loss: 0.916508:	
epoch: 301.000000:	train_loss: 1.086413:	test_loss: 0.916556:	
epoch: 302.000000:	train_loss: 1.093847:	test_loss: 0.922849:	
epoch: 303.000000:	train_loss: 1.091067:	test_loss: 0.925823:	
epoch: 304.000000:	train_loss: 1.089335:	test_loss: 0.927385:	
epoch: 305.000000:	train_loss: 1.086615:	test_loss: 0.914684:	
epoch: 306.000000:	train_loss: 1.089088:	test_loss: 0.919867:	
epoch: 307.000000:	train_loss: 1.083541:	test_loss: 0.953426:	
epoch: 308.000000:	train_loss: 1.088212:	test_loss: 0.942366:	
epoch: 309.000000:	train_loss: 1.088684:	test_loss: 0.926674:	
epoch: 310.000000:	train_loss: 1.084827:	test_loss: 0.923262:	
epoch: 311.000000:	train_loss: 1.087820:	test_loss: 0.942695:	
epoch: 312.000000:	train_loss: 1.089144:	test_loss: 0.924258:	
epoch: 313.000000:	train_loss: 1.083900:	test_loss: 0.936099:	
epoch: 314.000000:	train_loss: 1.088098:	test_loss: 0.929209:	
epoch: 315.000000:	train_loss: 1.082986:	test_loss: 0.930000:	
epoch: 316.000000:	train_loss: 1.085117:	test_loss: 0.920245:	
epoch: 317.000000:	train_loss: 1.086565:	test_loss: 0.917696:	
epoch: 318.000000:	train_loss: 1.082523:	test_loss: 0.922493:	
epoch: 319.000000:	train_loss: 1.085601:	test_loss: 0.914819:	
epoch: 320.000000:	train_loss: 1.085083:	test_loss: 0.932599:	
epoch: 321.000000:	train_loss: 1.083893:	test_loss: 0.926041:	
epoch: 322.000000:	train_loss: 1.083651:	test_loss: 0.947496:	
epoch: 323.000000:	train_loss: 1.084876:	test_loss: 0.941069:	
epoch: 324.000000:	train_loss: 1.082242:	test_loss: 0.926999:	
epoch: 325.000000:	train_loss: 1.087184:	test_loss: 0.928220:	
epoch: 326.000000:	train_loss: 1.083644:	test_loss: 0.922869:	
epoch: 327.000000:	train_loss: 1.083030:	test_loss: 0.924453:	
epoch: 328.000000:	train_loss: 1.086514:	test_loss: 0.916300:	
epoch: 329.000000:	train_loss: 1.084524:	test_loss: 0.932519:	
epoch: 330.000000:	train_loss: 1.085161:	test_loss: 0.946360:	
epoch: 331.000000:	train_loss: 1.088425:	test_loss: 0.914909:	
epoch: 332.000000:	train_loss: 1.085680:	test_loss: 0.932242:	
epoch: 333.000000:	train_loss: 1.077764:	test_loss: 0.920618:	
epoch: 334.000000:	train_loss: 1.086809:	test_loss: 0.917124:	
epoch: 335.000000:	train_loss: 1.085079:	test_loss: 0.919929:	
epoch: 336.000000:	train_loss: 1.083691:	test_loss: 0.922738:	
epoch: 337.000000:	train_loss: 1.082845:	test_loss: 0.925672:	
epoch: 338.000000:	train_loss: 1.080180:	test_loss: 0.923959:	
epoch: 339.000000:	train_loss: 1.084126:	test_loss: 0.916725:	
epoch: 340.000000:	train_loss: 1.082962:	test_loss: 0.932691:	
epoch: 341.000000:	train_loss: 1.086257:	test_loss: 0.939981:	
epoch: 342.000000:	train_loss: 1.081407:	test_loss: 0.928610:	
epoch: 343.000000:	train_loss: 1.084293:	test_loss: 0.926544:	
epoch: 344.000000:	train_loss: 1.079016:	test_loss: 0.912591:	
epoch: 345.000000:	train_loss: 1.084342:	test_loss: 0.931734:	
epoch: 346.000000:	train_loss: 1.081868:	test_loss: 0.924933:	
epoch: 347.000000:	train_loss: 1.083519:	test_loss: 0.923448:	
epoch: 348.000000:	train_loss: 1.087268:	test_loss: 0.921935:	
epoch: 349.000000:	train_loss: 1.087196:	test_loss: 0.912072:	
epoch: 350.000000:	train_loss: 1.082011:	test_loss: 0.922188:	
epoch: 351.000000:	train_loss: 1.085875:	test_loss: 0.919599:	
epoch: 352.000000:	train_loss: 1.082943:	test_loss: 0.923885:	
epoch: 353.000000:	train_loss: 1.082537:	test_loss: 0.923681:	
epoch: 354.000000:	train_loss: 1.077953:	test_loss: 0.913280:	
epoch: 355.000000:	train_loss: 1.077905:	test_loss: 0.919536:	
epoch: 356.000000:	train_loss: 1.084980:	test_loss: 0.915065:	
epoch: 357.000000:	train_loss: 1.083524:	test_loss: 0.921066:	
epoch: 358.000000:	train_loss: 1.079814:	test_loss: 0.916883:	
epoch: 359.000000:	train_loss: 1.080499:	test_loss: 0.919201:	
epoch: 360.000000:	train_loss: 1.083227:	test_loss: 0.927915:	
epoch: 361.000000:	train_loss: 1.084276:	test_loss: 0.911796:	
epoch: 362.000000:	train_loss: 1.081120:	test_loss: 0.924642:	
epoch: 363.000000:	train_loss: 1.082989:	test_loss: 0.913644:	
epoch: 364.000000:	train_loss: 1.081391:	test_loss: 0.917714:	
epoch: 365.000000:	train_loss: 1.079117:	test_loss: 0.913236:	
epoch: 366.000000:	train_loss: 1.081544:	test_loss: 0.910701:	
epoch: 367.000000:	train_loss: 1.085953:	test_loss: 0.919306:	
epoch: 368.000000:	train_loss: 1.079341:	test_loss: 0.925916:	
epoch: 369.000000:	train_loss: 1.084599:	test_loss: 0.929803:	
epoch: 370.000000:	train_loss: 1.082054:	test_loss: 0.924846:	
epoch: 371.000000:	train_loss: 1.081974:	test_loss: 0.912915:	
epoch: 372.000000:	train_loss: 1.078983:	test_loss: 0.918046:	
epoch: 373.000000:	train_loss: 1.081363:	test_loss: 0.918462:	
epoch: 374.000000:	train_loss: 1.076780:	test_loss: 0.911463:	
epoch: 375.000000:	train_loss: 1.081252:	test_loss: 0.928001:	
epoch: 376.000000:	train_loss: 1.080821:	test_loss: 0.914942:	
epoch: 377.000000:	train_loss: 1.082974:	test_loss: 0.911021:	
epoch: 378.000000:	train_loss: 1.080995:	test_loss: 0.924729:	
epoch: 379.000000:	train_loss: 1.080856:	test_loss: 0.932671:	
epoch: 380.000000:	train_loss: 1.082848:	test_loss: 0.910836:	
epoch: 381.000000:	train_loss: 1.082474:	test_loss: 0.930472:	
epoch: 382.000000:	train_loss: 1.080847:	test_loss: 0.904905:	
epoch: 383.000000:	train_loss: 1.080085:	test_loss: 0.911860:	
epoch: 384.000000:	train_loss: 1.079358:	test_loss: 0.914641:	
epoch: 385.000000:	train_loss: 1.082590:	test_loss: 0.910852:	
epoch: 386.000000:	train_loss: 1.079526:	test_loss: 0.913664:	
epoch: 387.000000:	train_loss: 1.077479:	test_loss: 0.921728:	
epoch: 388.000000:	train_loss: 1.081233:	test_loss: 0.913037:	
epoch: 389.000000:	train_loss: 1.078989:	test_loss: 0.911019:	
epoch: 390.000000:	train_loss: 1.082595:	test_loss: 0.916744:	
epoch: 391.000000:	train_loss: 1.081727:	test_loss: 0.923556:	
epoch: 392.000000:	train_loss: 1.079078:	test_loss: 0.936912:	
epoch: 393.000000:	train_loss: 1.081408:	test_loss: 0.909076:	
epoch: 394.000000:	train_loss: 1.084985:	test_loss: 0.917343:	
epoch: 395.000000:	train_loss: 1.081589:	test_loss: 0.912531:	
epoch: 396.000000:	train_loss: 1.078393:	test_loss: 0.927761:	
epoch: 397.000000:	train_loss: 1.083832:	test_loss: 0.910285:	
epoch: 398.000000:	train_loss: 1.080470:	test_loss: 0.912111:	
epoch: 399.000000:	train_loss: 1.078640:	test_loss: 0.917123:	
epoch: 400.000000:	train_loss: 1.079716:	test_loss: 0.917920:	
epoch: 401.000000:	train_loss: 1.079223:	test_loss: 0.909462:	
epoch: 402.000000:	train_loss: 1.080223:	test_loss: 0.911918:	
epoch: 403.000000:	train_loss: 1.080836:	test_loss: 0.925556:	
epoch: 404.000000:	train_loss: 1.077407:	test_loss: 0.915716:	
epoch: 405.000000:	train_loss: 1.075663:	test_loss: 0.942220:	
epoch: 406.000000:	train_loss: 1.081081:	test_loss: 0.917859:	
epoch: 407.000000:	train_loss: 1.079372:	test_loss: 0.914970:	
epoch: 408.000000:	train_loss: 1.077189:	test_loss: 0.910436:	
epoch: 409.000000:	train_loss: 1.076223:	test_loss: 0.916283:	
epoch: 410.000000:	train_loss: 1.080898:	test_loss: 0.923318:	
epoch: 411.000000:	train_loss: 1.079445:	test_loss: 0.921874:	
epoch: 412.000000:	train_loss: 1.080477:	test_loss: 0.912382:	
epoch: 413.000000:	train_loss: 1.080013:	test_loss: 0.916008:	
epoch: 414.000000:	train_loss: 1.077872:	test_loss: 0.915199:	
epoch: 415.000000:	train_loss: 1.083215:	test_loss: 0.927440:	
epoch: 416.000000:	train_loss: 1.077220:	test_loss: 0.915951:	
epoch: 417.000000:	train_loss: 1.076871:	test_loss: 0.940612:	
epoch: 418.000000:	train_loss: 1.078672:	test_loss: 0.914198:	
epoch: 419.000000:	train_loss: 1.080072:	test_loss: 0.909690:	
epoch: 420.000000:	train_loss: 1.081354:	test_loss: 0.938087:	
epoch: 421.000000:	train_loss: 1.080366:	test_loss: 0.910766:	
epoch: 422.000000:	train_loss: 1.078090:	test_loss: 0.914944:	
epoch: 423.000000:	train_loss: 1.077623:	test_loss: 0.919342:	
epoch: 424.000000:	train_loss: 1.081984:	test_loss: 0.909397:	
epoch: 425.000000:	train_loss: 1.081642:	test_loss: 0.906634:	
epoch: 426.000000:	train_loss: 1.077198:	test_loss: 0.912977:	
epoch: 427.000000:	train_loss: 1.079299:	test_loss: 0.923018:	
epoch: 428.000000:	train_loss: 1.082131:	test_loss: 0.908465:	
epoch: 429.000000:	train_loss: 1.077780:	test_loss: 0.909977:	
epoch: 430.000000:	train_loss: 1.076414:	test_loss: 0.915836:	
epoch: 431.000000:	train_loss: 1.080082:	test_loss: 0.910655:	
epoch: 432.000000:	train_loss: 1.077487:	test_loss: 0.912930:	
epoch: 433.000000:	train_loss: 1.074000:	test_loss: 0.913220:	
epoch: 434.000000:	train_loss: 1.075274:	test_loss: 0.910240:	
epoch: 435.000000:	train_loss: 1.077326:	test_loss: 0.908626:	
epoch: 436.000000:	train_loss: 1.080358:	test_loss: 0.907910:	
epoch: 437.000000:	train_loss: 1.081875:	test_loss: 0.916408:	
epoch: 438.000000:	train_loss: 1.081880:	test_loss: 0.921826:	
epoch: 439.000000:	train_loss: 1.077515:	test_loss: 0.907223:	
epoch: 440.000000:	train_loss: 1.077276:	test_loss: 0.911155:	
epoch: 441.000000:	train_loss: 1.082272:	test_loss: 0.921508:	
epoch: 442.000000:	train_loss: 1.078440:	test_loss: 0.910248:	
epoch: 443.000000:	train_loss: 1.079418:	test_loss: 0.946002:	
epoch: 444.000000:	train_loss: 1.079953:	test_loss: 0.908836:	
epoch: 445.000000:	train_loss: 1.078626:	test_loss: 0.917689:	
epoch: 446.000000:	train_loss: 1.075961:	test_loss: 0.908399:	
epoch: 447.000000:	train_loss: 1.080299:	test_loss: 0.924350:	
epoch: 448.000000:	train_loss: 1.083107:	test_loss: 0.926819:	
epoch: 449.000000:	train_loss: 1.082186:	test_loss: 0.909292:	
epoch: 450.000000:	train_loss: 1.080578:	test_loss: 0.908605:	
epoch: 451.000000:	train_loss: 1.076060:	test_loss: 0.916205:	
epoch: 452.000000:	train_loss: 1.079003:	test_loss: 0.909899:	
epoch: 453.000000:	train_loss: 1.081040:	test_loss: 0.912781:	
epoch: 454.000000:	train_loss: 1.077983:	test_loss: 0.910850:	
epoch: 455.000000:	train_loss: 1.079267:	test_loss: 0.919457:	
epoch: 456.000000:	train_loss: 1.081344:	test_loss: 0.919427:	
epoch: 457.000000:	train_loss: 1.077271:	test_loss: 0.917196:	
epoch: 458.000000:	train_loss: 1.079895:	test_loss: 0.918837:	
epoch: 459.000000:	train_loss: 1.076767:	test_loss: 0.927499:	
epoch: 460.000000:	train_loss: 1.078437:	test_loss: 0.912830:	
epoch: 461.000000:	train_loss: 1.077819:	test_loss: 0.916424:	
epoch: 462.000000:	train_loss: 1.080097:	test_loss: 0.930776:	
epoch: 463.000000:	train_loss: 1.076748:	test_loss: 0.910092:	
epoch: 464.000000:	train_loss: 1.077102:	test_loss: 0.905369:	
epoch: 465.000000:	train_loss: 1.081055:	test_loss: 0.913069:	
epoch: 466.000000:	train_loss: 1.077642:	test_loss: 0.911801:	
epoch: 467.000000:	train_loss: 1.073350:	test_loss: 0.905606:	
epoch: 468.000000:	train_loss: 1.078486:	test_loss: 0.923104:	
epoch: 469.000000:	train_loss: 1.076632:	test_loss: 0.908242:	
epoch: 470.000000:	train_loss: 1.073926:	test_loss: 0.907724:	
epoch: 471.000000:	train_loss: 1.074899:	test_loss: 0.908976:	
epoch: 472.000000:	train_loss: 1.076740:	test_loss: 0.932275:	
epoch: 473.000000:	train_loss: 1.082610:	test_loss: 0.918979:	
epoch: 474.000000:	train_loss: 1.077869:	test_loss: 0.920109:	
epoch: 475.000000:	train_loss: 1.077459:	test_loss: 0.924541:	
epoch: 476.000000:	train_loss: 1.075964:	test_loss: 0.908389:	
epoch: 477.000000:	train_loss: 1.078238:	test_loss: 0.920710:	
epoch: 478.000000:	train_loss: 1.077091:	test_loss: 0.923853:	
epoch: 479.000000:	train_loss: 1.082596:	test_loss: 0.930704:	
epoch: 480.000000:	train_loss: 1.082807:	test_loss: 0.908257:	
epoch: 481.000000:	train_loss: 1.078517:	test_loss: 0.911211:	
epoch: 482.000000:	train_loss: 1.077291:	test_loss: 0.908911:	
epoch: 483.000000:	train_loss: 1.079906:	test_loss: 0.915689:	
epoch: 484.000000:	train_loss: 1.077966:	test_loss: 0.908479:	
epoch: 485.000000:	train_loss: 1.076581:	test_loss: 0.915380:	
epoch: 486.000000:	train_loss: 1.076250:	test_loss: 0.924991:	
epoch: 487.000000:	train_loss: 1.079131:	test_loss: 0.911344:	
epoch: 488.000000:	train_loss: 1.079488:	test_loss: 0.926106:	
epoch: 489.000000:	train_loss: 1.080679:	test_loss: 0.907922:	
epoch: 490.000000:	train_loss: 1.079892:	test_loss: 0.908160:	
epoch: 491.000000:	train_loss: 1.077065:	test_loss: 0.911564:	
epoch: 492.000000:	train_loss: 1.079906:	test_loss: 0.921810:	
epoch: 493.000000:	train_loss: 1.076044:	test_loss: 0.913995:	
epoch: 494.000000:	train_loss: 1.079494:	test_loss: 0.916895:	
epoch: 495.000000:	train_loss: 1.079723:	test_loss: 0.916092:	
epoch: 496.000000:	train_loss: 1.077286:	test_loss: 0.908037:	
epoch: 497.000000:	train_loss: 1.082228:	test_loss: 0.923892:	
epoch: 498.000000:	train_loss: 1.077607:	test_loss: 0.919804:	
epoch: 499.000000:	train_loss: 1.079204:	test_loss: 0.912919:	
