epoch: 0.000000:	train_loss: 0.959408:	test_loss: 2.131335:	
epoch: 1.000000:	train_loss: 1.400527:	test_loss: 1.344205:	
epoch: 2.000000:	train_loss: 1.299778:	test_loss: 1.335898:	
epoch: 3.000000:	train_loss: 1.244031:	test_loss: 1.130785:	
epoch: 4.000000:	train_loss: 1.144210:	test_loss: 1.033869:	
epoch: 5.000000:	train_loss: 1.092624:	test_loss: 1.027687:	
epoch: 6.000000:	train_loss: 1.080106:	test_loss: 0.998028:	
epoch: 7.000000:	train_loss: 1.071171:	test_loss: 1.016961:	
epoch: 8.000000:	train_loss: 1.049593:	test_loss: 0.966102:	
epoch: 9.000000:	train_loss: 1.045139:	test_loss: 0.970431:	
epoch: 10.000000:	train_loss: 1.032291:	test_loss: 1.034978:	
epoch: 11.000000:	train_loss: 1.026342:	test_loss: 0.944081:	
epoch: 12.000000:	train_loss: 1.019815:	test_loss: 0.952495:	
epoch: 13.000000:	train_loss: 1.014255:	test_loss: 0.963369:	
epoch: 14.000000:	train_loss: 1.021431:	test_loss: 0.936690:	
epoch: 15.000000:	train_loss: 1.010037:	test_loss: 0.938141:	
epoch: 16.000000:	train_loss: 1.008337:	test_loss: 0.948067:	
epoch: 17.000000:	train_loss: 1.000190:	test_loss: 0.953387:	
epoch: 18.000000:	train_loss: 1.002887:	test_loss: 0.922441:	
epoch: 19.000000:	train_loss: 1.003602:	test_loss: 0.916168:	
epoch: 20.000000:	train_loss: 0.994398:	test_loss: 0.915929:	
epoch: 21.000000:	train_loss: 0.998942:	test_loss: 0.911666:	
epoch: 22.000000:	train_loss: 0.992364:	test_loss: 0.900154:	
epoch: 23.000000:	train_loss: 0.989596:	test_loss: 0.915313:	
epoch: 24.000000:	train_loss: 0.989022:	test_loss: 0.910355:	
epoch: 25.000000:	train_loss: 0.992480:	test_loss: 0.895351:	
epoch: 26.000000:	train_loss: 0.992837:	test_loss: 0.908141:	
epoch: 27.000000:	train_loss: 0.999197:	test_loss: 0.949578:	
epoch: 28.000000:	train_loss: 0.992068:	test_loss: 0.922347:	
epoch: 29.000000:	train_loss: 0.983343:	test_loss: 0.902952:	
epoch: 30.000000:	train_loss: 0.986769:	test_loss: 0.902521:	
epoch: 31.000000:	train_loss: 0.989826:	test_loss: 0.896407:	
epoch: 32.000000:	train_loss: 0.984691:	test_loss: 0.907079:	
epoch: 33.000000:	train_loss: 0.978814:	test_loss: 0.910763:	
epoch: 34.000000:	train_loss: 0.988506:	test_loss: 0.901830:	
epoch: 35.000000:	train_loss: 0.973988:	test_loss: 0.915166:	
epoch: 36.000000:	train_loss: 0.976002:	test_loss: 0.911220:	
epoch: 37.000000:	train_loss: 0.976542:	test_loss: 0.898137:	
epoch: 38.000000:	train_loss: 0.974507:	test_loss: 0.894684:	
epoch: 39.000000:	train_loss: 0.975961:	test_loss: 0.896925:	
epoch: 40.000000:	train_loss: 0.977243:	test_loss: 0.891939:	
epoch: 41.000000:	train_loss: 0.976948:	test_loss: 0.890693:	
epoch: 42.000000:	train_loss: 0.974091:	test_loss: 0.891313:	
epoch: 43.000000:	train_loss: 0.967927:	test_loss: 0.889493:	
epoch: 44.000000:	train_loss: 0.961124:	test_loss: 0.881590:	
epoch: 45.000000:	train_loss: 0.964908:	test_loss: 0.885424:	
epoch: 46.000000:	train_loss: 0.962754:	test_loss: 0.884082:	
epoch: 47.000000:	train_loss: 0.963457:	test_loss: 0.886764:	
epoch: 48.000000:	train_loss: 0.959438:	test_loss: 0.886145:	
epoch: 49.000000:	train_loss: 0.955997:	test_loss: 0.889072:	
epoch: 50.000000:	train_loss: 0.963901:	test_loss: 0.878697:	
epoch: 51.000000:	train_loss: 0.965358:	test_loss: 0.882626:	
epoch: 52.000000:	train_loss: 0.959524:	test_loss: 0.882264:	
epoch: 53.000000:	train_loss: 0.959815:	test_loss: 0.875704:	
epoch: 54.000000:	train_loss: 0.960207:	test_loss: 0.888435:	
epoch: 55.000000:	train_loss: 0.952737:	test_loss: 0.873885:	
epoch: 56.000000:	train_loss: 0.957869:	test_loss: 0.895987:	
epoch: 57.000000:	train_loss: 0.956754:	test_loss: 0.883112:	
epoch: 58.000000:	train_loss: 0.957602:	test_loss: 0.870241:	
epoch: 59.000000:	train_loss: 0.957885:	test_loss: 0.885508:	
epoch: 60.000000:	train_loss: 0.952048:	test_loss: 0.871238:	
epoch: 61.000000:	train_loss: 0.950565:	test_loss: 0.859803:	
epoch: 62.000000:	train_loss: 0.953046:	test_loss: 0.876740:	
epoch: 63.000000:	train_loss: 0.954982:	test_loss: 0.893856:	
epoch: 64.000000:	train_loss: 0.952675:	test_loss: 0.860721:	
epoch: 65.000000:	train_loss: 0.947698:	test_loss: 0.890814:	
epoch: 66.000000:	train_loss: 0.949024:	test_loss: 0.883295:	
epoch: 67.000000:	train_loss: 0.950045:	test_loss: 0.865045:	
epoch: 68.000000:	train_loss: 0.956772:	test_loss: 0.872451:	
epoch: 69.000000:	train_loss: 0.954989:	test_loss: 0.885962:	
epoch: 70.000000:	train_loss: 0.949207:	test_loss: 0.860736:	
epoch: 71.000000:	train_loss: 0.955272:	test_loss: 0.862282:	
epoch: 72.000000:	train_loss: 0.947163:	test_loss: 0.855840:	
epoch: 73.000000:	train_loss: 0.949270:	test_loss: 0.858318:	
epoch: 74.000000:	train_loss: 0.949314:	test_loss: 0.860470:	
epoch: 75.000000:	train_loss: 0.949401:	test_loss: 0.862176:	
epoch: 76.000000:	train_loss: 0.947167:	test_loss: 0.863819:	
epoch: 77.000000:	train_loss: 0.950186:	test_loss: 0.866680:	
epoch: 78.000000:	train_loss: 0.946988:	test_loss: 0.862304:	
epoch: 79.000000:	train_loss: 0.946025:	test_loss: 0.868186:	
epoch: 80.000000:	train_loss: 0.948919:	test_loss: 0.861600:	
epoch: 81.000000:	train_loss: 0.950099:	test_loss: 0.869415:	
epoch: 82.000000:	train_loss: 0.950758:	test_loss: 0.854643:	
epoch: 83.000000:	train_loss: 0.946761:	test_loss: 0.868735:	
epoch: 84.000000:	train_loss: 0.948869:	test_loss: 0.854720:	
epoch: 85.000000:	train_loss: 0.946945:	test_loss: 0.860241:	
epoch: 86.000000:	train_loss: 0.951267:	test_loss: 0.858734:	
epoch: 87.000000:	train_loss: 0.938918:	test_loss: 0.864505:	
epoch: 88.000000:	train_loss: 0.935371:	test_loss: 0.861097:	
epoch: 89.000000:	train_loss: 0.943482:	test_loss: 0.870945:	
epoch: 90.000000:	train_loss: 0.938650:	test_loss: 0.860279:	
epoch: 91.000000:	train_loss: 0.941946:	test_loss: 0.851181:	
epoch: 92.000000:	train_loss: 0.937716:	test_loss: 0.848514:	
epoch: 93.000000:	train_loss: 0.949174:	test_loss: 0.866348:	
epoch: 94.000000:	train_loss: 0.947152:	test_loss: 0.873938:	
epoch: 95.000000:	train_loss: 0.949599:	test_loss: 0.868463:	
epoch: 96.000000:	train_loss: 0.944782:	test_loss: 0.858892:	
epoch: 97.000000:	train_loss: 0.941232:	test_loss: 0.861650:	
epoch: 98.000000:	train_loss: 0.932013:	test_loss: 0.861933:	
epoch: 99.000000:	train_loss: 0.942057:	test_loss: 0.866189:	
epoch: 100.000000:	train_loss: 0.936648:	test_loss: 0.862268:	
epoch: 101.000000:	train_loss: 0.939865:	test_loss: 0.864112:	
epoch: 102.000000:	train_loss: 0.933148:	test_loss: 0.859933:	
epoch: 103.000000:	train_loss: 0.939012:	test_loss: 0.849491:	
epoch: 104.000000:	train_loss: 0.951493:	test_loss: 0.876406:	
epoch: 105.000000:	train_loss: 0.943284:	test_loss: 0.869690:	
epoch: 106.000000:	train_loss: 0.939058:	test_loss: 0.856468:	
epoch: 107.000000:	train_loss: 0.936266:	test_loss: 0.850606:	
epoch: 108.000000:	train_loss: 0.935443:	test_loss: 0.846765:	
epoch: 109.000000:	train_loss: 0.940890:	test_loss: 0.852253:	
epoch: 110.000000:	train_loss: 0.937484:	test_loss: 0.871826:	
epoch: 111.000000:	train_loss: 0.939891:	test_loss: 0.889154:	
epoch: 112.000000:	train_loss: 0.930206:	test_loss: 0.850008:	
epoch: 113.000000:	train_loss: 0.935723:	test_loss: 0.854410:	
epoch: 114.000000:	train_loss: 0.931776:	test_loss: 0.851773:	
epoch: 115.000000:	train_loss: 0.931443:	test_loss: 0.854359:	
epoch: 116.000000:	train_loss: 0.935884:	test_loss: 0.859308:	
epoch: 117.000000:	train_loss: 0.928160:	test_loss: 0.846800:	
epoch: 118.000000:	train_loss: 0.931385:	test_loss: 0.855121:	
epoch: 119.000000:	train_loss: 0.935839:	test_loss: 0.852128:	
epoch: 120.000000:	train_loss: 0.931272:	test_loss: 0.847638:	
epoch: 121.000000:	train_loss: 0.930554:	test_loss: 0.854488:	
epoch: 122.000000:	train_loss: 0.936682:	test_loss: 0.860550:	
epoch: 123.000000:	train_loss: 0.930503:	test_loss: 0.849045:	
epoch: 124.000000:	train_loss: 0.929965:	test_loss: 0.857992:	
epoch: 125.000000:	train_loss: 0.929063:	test_loss: 0.849273:	
epoch: 126.000000:	train_loss: 0.929084:	test_loss: 0.850532:	
epoch: 127.000000:	train_loss: 0.931762:	test_loss: 0.848584:	
epoch: 128.000000:	train_loss: 0.929831:	test_loss: 0.854292:	
epoch: 129.000000:	train_loss: 0.931571:	test_loss: 0.846019:	
epoch: 130.000000:	train_loss: 0.934873:	test_loss: 0.843354:	
epoch: 131.000000:	train_loss: 0.933679:	test_loss: 0.843703:	
epoch: 132.000000:	train_loss: 0.929567:	test_loss: 0.856082:	
epoch: 133.000000:	train_loss: 0.933997:	test_loss: 0.852407:	
epoch: 134.000000:	train_loss: 0.928283:	test_loss: 0.847698:	
epoch: 135.000000:	train_loss: 0.929105:	test_loss: 0.854336:	
epoch: 136.000000:	train_loss: 0.921144:	test_loss: 0.843537:	
epoch: 137.000000:	train_loss: 0.921849:	test_loss: 0.873212:	
epoch: 138.000000:	train_loss: 0.926721:	test_loss: 0.848081:	
epoch: 139.000000:	train_loss: 0.923097:	test_loss: 0.846693:	
epoch: 140.000000:	train_loss: 0.924729:	test_loss: 0.856198:	
epoch: 141.000000:	train_loss: 0.927661:	test_loss: 0.848613:	
epoch: 142.000000:	train_loss: 0.927793:	test_loss: 0.846829:	
epoch: 143.000000:	train_loss: 0.930764:	test_loss: 0.859598:	
epoch: 144.000000:	train_loss: 0.926279:	test_loss: 0.856472:	
epoch: 145.000000:	train_loss: 0.929031:	test_loss: 0.844555:	
epoch: 146.000000:	train_loss: 0.923661:	test_loss: 0.841965:	
epoch: 147.000000:	train_loss: 0.928601:	test_loss: 0.837896:	
epoch: 148.000000:	train_loss: 0.921163:	test_loss: 0.842681:	
epoch: 149.000000:	train_loss: 0.926579:	test_loss: 0.839941:	
epoch: 150.000000:	train_loss: 0.925133:	test_loss: 0.845616:	
epoch: 151.000000:	train_loss: 0.923525:	test_loss: 0.846422:	
epoch: 152.000000:	train_loss: 0.939570:	test_loss: 0.867466:	
epoch: 153.000000:	train_loss: 0.937866:	test_loss: 0.863706:	
epoch: 154.000000:	train_loss: 0.938345:	test_loss: 0.843707:	
epoch: 155.000000:	train_loss: 0.929142:	test_loss: 0.847227:	
epoch: 156.000000:	train_loss: 0.922143:	test_loss: 0.857233:	
epoch: 157.000000:	train_loss: 0.931496:	test_loss: 0.843692:	
epoch: 158.000000:	train_loss: 0.936233:	test_loss: 0.851459:	
epoch: 159.000000:	train_loss: 0.930080:	test_loss: 0.842464:	
epoch: 160.000000:	train_loss: 0.930701:	test_loss: 0.842169:	
epoch: 161.000000:	train_loss: 0.923712:	test_loss: 0.848180:	
epoch: 162.000000:	train_loss: 0.920501:	test_loss: 0.846530:	
epoch: 163.000000:	train_loss: 0.917833:	test_loss: 0.846347:	
epoch: 164.000000:	train_loss: 0.922373:	test_loss: 0.847611:	
epoch: 165.000000:	train_loss: 0.919426:	test_loss: 0.840963:	
epoch: 166.000000:	train_loss: 0.918347:	test_loss: 0.843945:	
epoch: 167.000000:	train_loss: 0.926159:	test_loss: 0.840949:	
epoch: 168.000000:	train_loss: 0.918610:	test_loss: 0.843790:	
epoch: 169.000000:	train_loss: 0.923523:	test_loss: 0.854015:	
epoch: 170.000000:	train_loss: 0.921433:	test_loss: 0.841960:	
epoch: 171.000000:	train_loss: 0.924654:	test_loss: 0.854543:	
epoch: 172.000000:	train_loss: 0.921248:	test_loss: 0.845579:	
epoch: 173.000000:	train_loss: 0.921033:	test_loss: 0.843527:	
epoch: 174.000000:	train_loss: 0.926446:	test_loss: 0.853819:	
epoch: 175.000000:	train_loss: 0.919470:	test_loss: 0.841282:	
epoch: 176.000000:	train_loss: 0.919701:	test_loss: 0.837798:	
epoch: 177.000000:	train_loss: 0.915835:	test_loss: 0.841078:	
epoch: 178.000000:	train_loss: 0.921041:	test_loss: 0.863244:	
epoch: 179.000000:	train_loss: 0.921370:	test_loss: 0.844249:	
epoch: 180.000000:	train_loss: 0.916716:	test_loss: 0.839787:	
epoch: 181.000000:	train_loss: 0.916939:	test_loss: 0.835339:	
epoch: 182.000000:	train_loss: 0.921909:	test_loss: 0.839065:	
epoch: 183.000000:	train_loss: 0.920324:	test_loss: 0.845444:	
epoch: 184.000000:	train_loss: 0.920844:	test_loss: 0.839701:	
epoch: 185.000000:	train_loss: 0.919804:	test_loss: 0.840674:	
epoch: 186.000000:	train_loss: 0.916669:	test_loss: 0.839848:	
epoch: 187.000000:	train_loss: 0.921720:	test_loss: 0.851043:	
epoch: 188.000000:	train_loss: 0.918549:	test_loss: 0.840049:	
epoch: 189.000000:	train_loss: 0.915727:	test_loss: 0.840169:	
epoch: 190.000000:	train_loss: 0.922556:	test_loss: 0.834733:	
epoch: 191.000000:	train_loss: 0.915435:	test_loss: 0.842582:	
epoch: 192.000000:	train_loss: 0.911701:	test_loss: 0.842060:	
epoch: 193.000000:	train_loss: 0.909627:	test_loss: 0.844694:	
epoch: 194.000000:	train_loss: 0.917434:	test_loss: 0.830954:	
epoch: 195.000000:	train_loss: 0.919072:	test_loss: 0.834296:	
epoch: 196.000000:	train_loss: 0.916260:	test_loss: 0.832263:	
epoch: 197.000000:	train_loss: 0.921191:	test_loss: 0.835628:	
epoch: 198.000000:	train_loss: 0.914522:	test_loss: 0.834884:	
epoch: 199.000000:	train_loss: 0.918843:	test_loss: 0.833390:	
epoch: 200.000000:	train_loss: 0.910061:	test_loss: 0.829485:	
epoch: 201.000000:	train_loss: 0.908799:	test_loss: 0.836387:	
epoch: 202.000000:	train_loss: 0.911590:	test_loss: 0.837230:	
epoch: 203.000000:	train_loss: 0.912435:	test_loss: 0.838520:	
epoch: 204.000000:	train_loss: 0.911364:	test_loss: 0.839805:	
epoch: 205.000000:	train_loss: 0.912373:	test_loss: 0.844200:	
epoch: 206.000000:	train_loss: 0.916218:	test_loss: 0.836898:	
epoch: 207.000000:	train_loss: 0.917782:	test_loss: 0.830326:	
epoch: 208.000000:	train_loss: 0.920715:	test_loss: 0.841372:	
epoch: 209.000000:	train_loss: 0.909497:	test_loss: 0.835142:	
epoch: 210.000000:	train_loss: 0.911993:	test_loss: 0.827918:	
epoch: 211.000000:	train_loss: 0.908753:	test_loss: 0.832840:	
epoch: 212.000000:	train_loss: 0.924818:	test_loss: 0.856883:	
epoch: 213.000000:	train_loss: 0.922321:	test_loss: 0.836181:	
epoch: 214.000000:	train_loss: 0.921702:	test_loss: 0.836284:	
epoch: 215.000000:	train_loss: 0.913344:	test_loss: 0.835042:	
epoch: 216.000000:	train_loss: 0.910669:	test_loss: 0.831757:	
epoch: 217.000000:	train_loss: 0.914551:	test_loss: 0.832840:	
epoch: 218.000000:	train_loss: 0.908323:	test_loss: 0.844931:	
epoch: 219.000000:	train_loss: 0.918504:	test_loss: 0.835917:	
epoch: 220.000000:	train_loss: 0.908342:	test_loss: 0.833505:	
epoch: 221.000000:	train_loss: 0.911309:	test_loss: 0.844682:	
epoch: 222.000000:	train_loss: 0.916079:	test_loss: 0.832946:	
epoch: 223.000000:	train_loss: 0.906663:	test_loss: 0.824982:	
epoch: 224.000000:	train_loss: 0.906667:	test_loss: 0.843218:	
epoch: 225.000000:	train_loss: 0.910393:	test_loss: 0.830785:	
epoch: 226.000000:	train_loss: 0.914537:	test_loss: 0.830736:	
epoch: 227.000000:	train_loss: 0.908831:	test_loss: 0.831528:	
epoch: 228.000000:	train_loss: 0.904625:	test_loss: 0.834880:	
epoch: 229.000000:	train_loss: 0.906983:	test_loss: 0.834944:	
epoch: 230.000000:	train_loss: 0.913508:	test_loss: 0.831844:	
epoch: 231.000000:	train_loss: 0.909705:	test_loss: 0.839201:	
epoch: 232.000000:	train_loss: 0.905776:	test_loss: 0.831074:	
epoch: 233.000000:	train_loss: 0.911227:	test_loss: 0.838176:	
epoch: 234.000000:	train_loss: 0.909852:	test_loss: 0.843466:	
epoch: 235.000000:	train_loss: 0.907317:	test_loss: 0.833734:	
epoch: 236.000000:	train_loss: 0.909173:	test_loss: 0.841737:	
epoch: 237.000000:	train_loss: 0.904281:	test_loss: 0.839110:	
epoch: 238.000000:	train_loss: 0.903742:	test_loss: 0.835933:	
epoch: 239.000000:	train_loss: 0.911773:	test_loss: 0.830567:	
epoch: 240.000000:	train_loss: 0.911145:	test_loss: 0.827032:	
epoch: 241.000000:	train_loss: 0.914100:	test_loss: 0.841505:	
epoch: 242.000000:	train_loss: 0.914828:	test_loss: 0.832132:	
epoch: 243.000000:	train_loss: 0.910089:	test_loss: 0.830312:	
epoch: 244.000000:	train_loss: 0.908173:	test_loss: 0.830922:	
epoch: 245.000000:	train_loss: 0.911537:	test_loss: 0.832754:	
epoch: 246.000000:	train_loss: 0.905724:	test_loss: 0.832859:	
epoch: 247.000000:	train_loss: 0.908646:	test_loss: 0.834456:	
epoch: 248.000000:	train_loss: 0.907863:	test_loss: 0.828791:	
epoch: 249.000000:	train_loss: 0.906681:	test_loss: 0.829219:	
epoch: 250.000000:	train_loss: 0.910116:	test_loss: 0.837704:	
epoch: 251.000000:	train_loss: 0.908032:	test_loss: 0.831127:	
epoch: 252.000000:	train_loss: 0.902153:	test_loss: 0.835751:	
epoch: 253.000000:	train_loss: 0.903661:	test_loss: 0.837374:	
epoch: 254.000000:	train_loss: 0.905929:	test_loss: 0.836253:	
epoch: 255.000000:	train_loss: 0.905515:	test_loss: 0.829043:	
epoch: 256.000000:	train_loss: 0.909032:	test_loss: 0.828459:	
epoch: 257.000000:	train_loss: 0.909878:	test_loss: 0.837460:	
epoch: 258.000000:	train_loss: 0.905300:	test_loss: 0.842448:	
epoch: 259.000000:	train_loss: 0.914012:	test_loss: 0.830455:	
epoch: 260.000000:	train_loss: 0.907563:	test_loss: 0.833017:	
epoch: 261.000000:	train_loss: 0.905844:	test_loss: 0.825617:	
epoch: 262.000000:	train_loss: 0.904687:	test_loss: 0.833854:	
epoch: 263.000000:	train_loss: 0.908245:	test_loss: 0.835936:	
epoch: 264.000000:	train_loss: 0.907326:	test_loss: 0.830472:	
epoch: 265.000000:	train_loss: 0.906347:	test_loss: 0.828242:	
epoch: 266.000000:	train_loss: 0.903533:	test_loss: 0.828841:	
epoch: 267.000000:	train_loss: 0.900228:	test_loss: 0.837824:	
epoch: 268.000000:	train_loss: 0.902227:	test_loss: 0.825164:	
epoch: 269.000000:	train_loss: 0.904827:	test_loss: 0.824963:	
epoch: 270.000000:	train_loss: 0.905166:	test_loss: 0.831112:	
epoch: 271.000000:	train_loss: 0.907133:	test_loss: 0.824674:	
epoch: 272.000000:	train_loss: 0.909372:	test_loss: 0.823897:	
epoch: 273.000000:	train_loss: 0.899284:	test_loss: 0.830089:	
epoch: 274.000000:	train_loss: 0.902506:	test_loss: 0.827580:	
epoch: 275.000000:	train_loss: 0.901123:	test_loss: 0.831059:	
epoch: 276.000000:	train_loss: 0.905734:	test_loss: 0.831149:	
epoch: 277.000000:	train_loss: 0.909230:	test_loss: 0.830184:	
epoch: 278.000000:	train_loss: 0.904083:	test_loss: 0.825938:	
epoch: 279.000000:	train_loss: 0.906447:	test_loss: 0.830905:	
epoch: 280.000000:	train_loss: 0.906350:	test_loss: 0.822917:	
epoch: 281.000000:	train_loss: 0.898042:	test_loss: 0.830148:	
epoch: 282.000000:	train_loss: 0.900719:	test_loss: 0.830251:	
epoch: 283.000000:	train_loss: 0.904916:	test_loss: 0.830431:	
epoch: 284.000000:	train_loss: 0.904827:	test_loss: 0.826883:	
epoch: 285.000000:	train_loss: 0.899668:	test_loss: 0.832327:	
epoch: 286.000000:	train_loss: 0.901456:	test_loss: 0.828137:	
epoch: 287.000000:	train_loss: 0.906574:	test_loss: 0.829175:	
epoch: 288.000000:	train_loss: 0.905327:	test_loss: 0.825031:	
epoch: 289.000000:	train_loss: 0.904134:	test_loss: 0.826860:	
epoch: 290.000000:	train_loss: 0.898962:	test_loss: 0.822227:	
epoch: 291.000000:	train_loss: 0.901091:	test_loss: 0.829113:	
epoch: 292.000000:	train_loss: 0.903279:	test_loss: 0.827539:	
epoch: 293.000000:	train_loss: 0.907591:	test_loss: 0.832146:	
epoch: 294.000000:	train_loss: 0.904949:	test_loss: 0.825241:	
epoch: 295.000000:	train_loss: 0.899764:	test_loss: 0.823565:	
epoch: 296.000000:	train_loss: 0.905864:	test_loss: 0.822779:	
epoch: 297.000000:	train_loss: 0.901985:	test_loss: 0.820379:	
epoch: 298.000000:	train_loss: 0.903727:	test_loss: 0.825750:	
epoch: 299.000000:	train_loss: 0.906162:	test_loss: 0.823227:	
epoch: 300.000000:	train_loss: 0.901091:	test_loss: 0.826127:	
epoch: 301.000000:	train_loss: 0.902086:	test_loss: 0.830081:	
epoch: 302.000000:	train_loss: 0.897773:	test_loss: 0.820667:	
epoch: 303.000000:	train_loss: 0.902021:	test_loss: 0.835328:	
epoch: 304.000000:	train_loss: 0.897685:	test_loss: 0.823154:	
epoch: 305.000000:	train_loss: 0.900374:	test_loss: 0.829011:	
epoch: 306.000000:	train_loss: 0.900238:	test_loss: 0.827179:	
epoch: 307.000000:	train_loss: 0.898523:	test_loss: 0.825640:	
epoch: 308.000000:	train_loss: 0.896277:	test_loss: 0.828430:	
epoch: 309.000000:	train_loss: 0.896610:	test_loss: 0.827267:	
epoch: 310.000000:	train_loss: 0.900427:	test_loss: 0.827753:	
epoch: 311.000000:	train_loss: 0.899985:	test_loss: 0.828481:	
epoch: 312.000000:	train_loss: 0.896930:	test_loss: 0.829084:	
epoch: 313.000000:	train_loss: 0.899377:	test_loss: 0.823894:	
epoch: 314.000000:	train_loss: 0.894559:	test_loss: 0.829082:	
epoch: 315.000000:	train_loss: 0.899842:	test_loss: 0.828135:	
epoch: 316.000000:	train_loss: 0.899108:	test_loss: 0.827454:	
epoch: 317.000000:	train_loss: 0.897877:	test_loss: 0.823565:	
epoch: 318.000000:	train_loss: 0.899994:	test_loss: 0.830299:	
epoch: 319.000000:	train_loss: 0.901640:	test_loss: 0.824783:	
epoch: 320.000000:	train_loss: 0.901507:	test_loss: 0.824108:	
epoch: 321.000000:	train_loss: 0.897488:	test_loss: 0.827081:	
epoch: 322.000000:	train_loss: 0.905137:	test_loss: 0.822871:	
epoch: 323.000000:	train_loss: 0.903308:	test_loss: 0.821984:	
epoch: 324.000000:	train_loss: 0.902024:	test_loss: 0.822455:	
epoch: 325.000000:	train_loss: 0.900328:	test_loss: 0.823756:	
epoch: 326.000000:	train_loss: 0.902540:	test_loss: 0.821140:	
epoch: 327.000000:	train_loss: 0.901873:	test_loss: 0.829579:	
epoch: 328.000000:	train_loss: 0.902023:	test_loss: 0.829302:	
epoch: 329.000000:	train_loss: 0.903460:	test_loss: 0.827988:	
epoch: 330.000000:	train_loss: 0.897440:	test_loss: 0.822589:	
epoch: 331.000000:	train_loss: 0.897980:	test_loss: 0.822122:	
epoch: 332.000000:	train_loss: 0.899761:	test_loss: 0.820164:	
epoch: 333.000000:	train_loss: 0.898337:	test_loss: 0.823131:	
epoch: 334.000000:	train_loss: 0.895032:	test_loss: 0.819381:	
epoch: 335.000000:	train_loss: 0.902319:	test_loss: 0.822338:	
epoch: 336.000000:	train_loss: 0.896204:	test_loss: 0.822333:	
epoch: 337.000000:	train_loss: 0.898456:	test_loss: 0.829252:	
epoch: 338.000000:	train_loss: 0.901541:	test_loss: 0.828664:	
epoch: 339.000000:	train_loss: 0.899872:	test_loss: 0.829311:	
epoch: 340.000000:	train_loss: 0.898368:	test_loss: 0.824225:	
epoch: 341.000000:	train_loss: 0.898206:	test_loss: 0.830451:	
epoch: 342.000000:	train_loss: 0.898192:	test_loss: 0.823925:	
epoch: 343.000000:	train_loss: 0.902225:	test_loss: 0.835565:	
epoch: 344.000000:	train_loss: 0.905073:	test_loss: 0.824404:	
epoch: 345.000000:	train_loss: 0.900568:	test_loss: 0.827232:	
epoch: 346.000000:	train_loss: 0.892897:	test_loss: 0.825089:	
epoch: 347.000000:	train_loss: 0.893035:	test_loss: 0.828135:	
epoch: 348.000000:	train_loss: 0.897267:	test_loss: 0.827322:	
epoch: 349.000000:	train_loss: 0.895520:	test_loss: 0.831455:	
epoch: 350.000000:	train_loss: 0.890904:	test_loss: 0.821372:	
epoch: 351.000000:	train_loss: 0.897095:	test_loss: 0.828853:	
epoch: 352.000000:	train_loss: 0.897759:	test_loss: 0.822422:	
epoch: 353.000000:	train_loss: 0.899908:	test_loss: 0.834559:	
epoch: 354.000000:	train_loss: 0.896657:	test_loss: 0.829845:	
epoch: 355.000000:	train_loss: 0.896666:	test_loss: 0.825048:	
epoch: 356.000000:	train_loss: 0.896172:	test_loss: 0.825366:	
epoch: 357.000000:	train_loss: 0.895332:	test_loss: 0.827709:	
epoch: 358.000000:	train_loss: 0.892269:	test_loss: 0.825737:	
epoch: 359.000000:	train_loss: 0.901444:	test_loss: 0.829653:	
epoch: 360.000000:	train_loss: 0.902450:	test_loss: 0.828861:	
epoch: 361.000000:	train_loss: 0.896086:	test_loss: 0.823958:	
epoch: 362.000000:	train_loss: 0.900549:	test_loss: 0.829028:	
epoch: 363.000000:	train_loss: 0.896422:	test_loss: 0.829085:	
epoch: 364.000000:	train_loss: 0.896071:	test_loss: 0.824819:	
epoch: 365.000000:	train_loss: 0.893974:	test_loss: 0.826689:	
epoch: 366.000000:	train_loss: 0.895129:	test_loss: 0.823978:	
epoch: 367.000000:	train_loss: 0.902887:	test_loss: 0.824877:	
epoch: 368.000000:	train_loss: 0.893706:	test_loss: 0.821554:	
epoch: 369.000000:	train_loss: 0.897723:	test_loss: 0.827443:	
epoch: 370.000000:	train_loss: 0.896727:	test_loss: 0.832282:	
epoch: 371.000000:	train_loss: 0.900847:	test_loss: 0.828277:	
epoch: 372.000000:	train_loss: 0.893021:	test_loss: 0.827745:	
epoch: 373.000000:	train_loss: 0.895160:	test_loss: 0.831335:	
epoch: 374.000000:	train_loss: 0.893960:	test_loss: 0.830767:	
epoch: 375.000000:	train_loss: 0.899117:	test_loss: 0.829169:	
epoch: 376.000000:	train_loss: 0.887669:	test_loss: 0.829886:	
epoch: 377.000000:	train_loss: 0.894327:	test_loss: 0.827216:	
epoch: 378.000000:	train_loss: 0.893916:	test_loss: 0.825973:	
epoch: 379.000000:	train_loss: 0.894582:	test_loss: 0.825669:	
epoch: 380.000000:	train_loss: 0.892753:	test_loss: 0.826368:	
epoch: 381.000000:	train_loss: 0.897098:	test_loss: 0.826930:	
epoch: 382.000000:	train_loss: 0.893098:	test_loss: 0.828431:	
epoch: 383.000000:	train_loss: 0.901237:	test_loss: 0.823675:	
epoch: 384.000000:	train_loss: 0.900481:	test_loss: 0.828513:	
epoch: 385.000000:	train_loss: 0.894897:	test_loss: 0.825018:	
epoch: 386.000000:	train_loss: 0.899898:	test_loss: 0.828655:	
epoch: 387.000000:	train_loss: 0.896050:	test_loss: 0.834515:	
epoch: 388.000000:	train_loss: 0.895654:	test_loss: 0.825741:	
epoch: 389.000000:	train_loss: 0.893436:	test_loss: 0.834686:	
epoch: 390.000000:	train_loss: 0.895572:	test_loss: 0.825844:	
epoch: 391.000000:	train_loss: 0.897009:	test_loss: 0.830806:	
epoch: 392.000000:	train_loss: 0.897842:	test_loss: 0.823546:	
epoch: 393.000000:	train_loss: 0.898550:	test_loss: 0.826218:	
epoch: 394.000000:	train_loss: 0.896243:	test_loss: 0.826264:	
epoch: 395.000000:	train_loss: 0.895030:	test_loss: 0.829454:	
epoch: 396.000000:	train_loss: 0.894742:	test_loss: 0.828907:	
epoch: 397.000000:	train_loss: 0.901856:	test_loss: 0.824043:	
epoch: 398.000000:	train_loss: 0.894570:	test_loss: 0.820228:	
epoch: 399.000000:	train_loss: 0.902639:	test_loss: 0.824354:	
epoch: 400.000000:	train_loss: 0.889747:	test_loss: 0.824858:	
epoch: 401.000000:	train_loss: 0.891880:	test_loss: 0.823205:	
epoch: 402.000000:	train_loss: 0.891508:	test_loss: 0.829837:	
epoch: 403.000000:	train_loss: 0.892619:	test_loss: 0.828716:	
epoch: 404.000000:	train_loss: 0.896706:	test_loss: 0.822744:	
epoch: 405.000000:	train_loss: 0.897315:	test_loss: 0.836231:	
epoch: 406.000000:	train_loss: 0.897901:	test_loss: 0.828045:	
epoch: 407.000000:	train_loss: 0.896365:	test_loss: 0.823721:	
epoch: 408.000000:	train_loss: 0.893575:	test_loss: 0.824311:	
epoch: 409.000000:	train_loss: 0.898245:	test_loss: 0.826958:	
epoch: 410.000000:	train_loss: 0.894181:	test_loss: 0.831845:	
epoch: 411.000000:	train_loss: 0.892422:	test_loss: 0.823317:	
epoch: 412.000000:	train_loss: 0.895076:	test_loss: 0.826970:	
epoch: 413.000000:	train_loss: 0.900958:	test_loss: 0.828496:	
epoch: 414.000000:	train_loss: 0.898506:	test_loss: 0.824720:	
epoch: 415.000000:	train_loss: 0.892044:	test_loss: 0.827169:	
epoch: 416.000000:	train_loss: 0.895178:	test_loss: 0.827947:	
epoch: 417.000000:	train_loss: 0.890923:	test_loss: 0.826489:	
epoch: 418.000000:	train_loss: 0.891569:	test_loss: 0.827892:	
epoch: 419.000000:	train_loss: 0.897692:	test_loss: 0.832377:	
epoch: 420.000000:	train_loss: 0.891744:	test_loss: 0.831758:	
epoch: 421.000000:	train_loss: 0.899971:	test_loss: 0.831023:	
epoch: 422.000000:	train_loss: 0.893354:	test_loss: 0.829854:	
epoch: 423.000000:	train_loss: 0.894422:	test_loss: 0.827081:	
epoch: 424.000000:	train_loss: 0.890891:	test_loss: 0.827129:	
epoch: 425.000000:	train_loss: 0.897284:	test_loss: 0.825118:	
epoch: 426.000000:	train_loss: 0.897119:	test_loss: 0.829851:	
epoch: 427.000000:	train_loss: 0.894552:	test_loss: 0.830125:	
epoch: 428.000000:	train_loss: 0.895053:	test_loss: 0.828225:	
epoch: 429.000000:	train_loss: 0.899212:	test_loss: 0.826715:	
epoch: 430.000000:	train_loss: 0.894052:	test_loss: 0.828223:	
epoch: 431.000000:	train_loss: 0.894632:	test_loss: 0.826338:	
epoch: 432.000000:	train_loss: 0.894991:	test_loss: 0.825151:	
epoch: 433.000000:	train_loss: 0.893042:	test_loss: 0.827478:	
epoch: 434.000000:	train_loss: 0.889665:	test_loss: 0.826590:	
epoch: 435.000000:	train_loss: 0.903153:	test_loss: 0.829260:	
epoch: 436.000000:	train_loss: 0.896815:	test_loss: 0.828672:	
epoch: 437.000000:	train_loss: 0.897345:	test_loss: 0.825538:	
epoch: 438.000000:	train_loss: 0.895511:	test_loss: 0.827716:	
epoch: 439.000000:	train_loss: 0.895765:	test_loss: 0.827987:	
epoch: 440.000000:	train_loss: 0.897609:	test_loss: 0.828945:	
epoch: 441.000000:	train_loss: 0.889085:	test_loss: 0.826846:	
epoch: 442.000000:	train_loss: 0.898628:	test_loss: 0.826593:	
epoch: 443.000000:	train_loss: 0.892049:	test_loss: 0.825878:	
epoch: 444.000000:	train_loss: 0.891285:	test_loss: 0.827064:	
epoch: 445.000000:	train_loss: 0.898060:	test_loss: 0.828243:	
epoch: 446.000000:	train_loss: 0.895935:	test_loss: 0.824091:	
epoch: 447.000000:	train_loss: 0.895873:	test_loss: 0.830068:	
epoch: 448.000000:	train_loss: 0.893032:	test_loss: 0.823694:	
epoch: 449.000000:	train_loss: 0.891521:	test_loss: 0.827738:	
epoch: 450.000000:	train_loss: 0.894198:	test_loss: 0.826848:	
epoch: 451.000000:	train_loss: 0.896942:	test_loss: 0.824373:	
epoch: 452.000000:	train_loss: 0.892400:	test_loss: 0.823716:	
epoch: 453.000000:	train_loss: 0.891999:	test_loss: 0.827893:	
epoch: 454.000000:	train_loss: 0.894550:	test_loss: 0.824519:	
epoch: 455.000000:	train_loss: 0.894879:	test_loss: 0.823555:	
epoch: 456.000000:	train_loss: 0.890760:	test_loss: 0.824390:	
epoch: 457.000000:	train_loss: 0.891423:	test_loss: 0.827679:	
epoch: 458.000000:	train_loss: 0.896821:	test_loss: 0.826819:	
epoch: 459.000000:	train_loss: 0.895175:	test_loss: 0.828013:	
epoch: 460.000000:	train_loss: 0.898688:	test_loss: 0.827743:	
epoch: 461.000000:	train_loss: 0.892444:	test_loss: 0.828218:	
epoch: 462.000000:	train_loss: 0.893920:	test_loss: 0.825218:	
epoch: 463.000000:	train_loss: 0.895474:	test_loss: 0.828882:	
epoch: 464.000000:	train_loss: 0.894787:	test_loss: 0.827157:	
epoch: 465.000000:	train_loss: 0.897323:	test_loss: 0.825966:	
epoch: 466.000000:	train_loss: 0.895492:	test_loss: 0.827831:	
epoch: 467.000000:	train_loss: 0.888299:	test_loss: 0.826245:	
epoch: 468.000000:	train_loss: 0.893326:	test_loss: 0.825609:	
epoch: 469.000000:	train_loss: 0.894353:	test_loss: 0.825937:	
epoch: 470.000000:	train_loss: 0.892031:	test_loss: 0.826472:	
epoch: 471.000000:	train_loss: 0.894147:	test_loss: 0.826778:	
epoch: 472.000000:	train_loss: 0.895585:	test_loss: 0.824766:	
epoch: 473.000000:	train_loss: 0.892919:	test_loss: 0.826054:	
epoch: 474.000000:	train_loss: 0.895603:	test_loss: 0.827223:	
epoch: 475.000000:	train_loss: 0.895323:	test_loss: 0.823797:	
epoch: 476.000000:	train_loss: 0.892124:	test_loss: 0.828256:	
epoch: 477.000000:	train_loss: 0.891932:	test_loss: 0.829947:	
epoch: 478.000000:	train_loss: 0.900522:	test_loss: 0.827473:	
epoch: 479.000000:	train_loss: 0.892324:	test_loss: 0.827715:	
epoch: 480.000000:	train_loss: 0.896810:	test_loss: 0.825786:	
epoch: 481.000000:	train_loss: 0.888595:	test_loss: 0.825052:	
epoch: 482.000000:	train_loss: 0.892365:	test_loss: 0.826611:	
epoch: 483.000000:	train_loss: 0.890904:	test_loss: 0.825193:	
epoch: 484.000000:	train_loss: 0.895630:	test_loss: 0.828115:	
epoch: 485.000000:	train_loss: 0.898155:	test_loss: 0.823278:	
epoch: 486.000000:	train_loss: 0.891287:	test_loss: 0.825533:	
epoch: 487.000000:	train_loss: 0.893089:	test_loss: 0.826026:	
epoch: 488.000000:	train_loss: 0.895402:	test_loss: 0.825809:	
epoch: 489.000000:	train_loss: 0.894726:	test_loss: 0.822996:	
epoch: 490.000000:	train_loss: 0.899740:	test_loss: 0.823896:	
epoch: 491.000000:	train_loss: 0.897320:	test_loss: 0.825661:	
epoch: 492.000000:	train_loss: 0.891700:	test_loss: 0.826160:	
epoch: 493.000000:	train_loss: 0.898319:	test_loss: 0.824756:	
epoch: 494.000000:	train_loss: 0.890316:	test_loss: 0.828515:	
epoch: 495.000000:	train_loss: 0.897270:	test_loss: 0.826133:	
epoch: 496.000000:	train_loss: 0.896516:	test_loss: 0.824971:	
epoch: 497.000000:	train_loss: 0.890908:	test_loss: 0.828727:	
epoch: 498.000000:	train_loss: 0.897369:	test_loss: 0.823602:	
epoch: 499.000000:	train_loss: 0.891041:	test_loss: 0.831580:	
